{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58531ecd",
   "metadata": {},
   "source": [
    "#### 0、导入库与读数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0057d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1df35874",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_product_path = 'req_train.csv'\n",
    "train_sale_path = 'order_train.csv'\n",
    "test_product_path = 'req_test.csv'\n",
    "test_sale_path = 'order_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2317314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_product = pd.read_csv(os.path.join(root_path, train_product_path))\n",
    "train_sale = pd.read_csv(os.path.join(root_path, train_sale_path))\n",
    "test_product = pd.read_csv(os.path.join(root_path, test_product_path))\n",
    "test_sale = pd.read_csv(os.path.join(root_path, test_sale_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ba56fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product = pd.concat([train_product, test_product]).reset_index(drop=True)\n",
    "df_sale = pd.concat([train_sale, test_sale]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ab2241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1129.,  3568.,  4560.,  7521.,  7687.,  8675.,  8245.,  7989.,\n",
       "        7583.,  8522.,  9310.,  7049.,  1101.,  4611.,  6769.,  9941.,\n",
       "       10689., 11824., 10986.,  9820., 10731., 12677., 14152.,  4469.,\n",
       "        2755.,  3048.,  7108., 12472., 13061., 15835., 14180., 15034.,\n",
       "       14312., 16180., 17381., 15182.,  1128., 10756., 13352., 15664.,\n",
       "       18329.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sale.order.unique()\n",
    "# 订单量指所有商品的总订单，而非某个商品的订单"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02e4828",
   "metadata": {},
   "source": [
    "#### 1、数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e78a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_label(df_product, is_train = False):\n",
    "    \n",
    "    df_product['date']  = df_product['date'].map(lambda x: x[:-3]).values\n",
    "    if is_train:\n",
    "        agg_dict = {'label':'sum',\n",
    "               'is_sale_day':{'sum','count'},\n",
    "              }\n",
    "    else:\n",
    "        agg_dict = {'is_sale_day':{'sum','count'}}\n",
    "    \n",
    "    df_label = df_product.groupby(['product_id','date']).agg(agg_dict) #### agg({'feature':'stat'}) max, min, sum, meadian, mean, std\n",
    "    df_label.columns = ['_'.join(x)  for x in df_label.columns]\n",
    "    df_label = df_label.reset_index()\n",
    "    return df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82217237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_label = _get_label(train_product,is_train = True)\n",
    "df_test_label  = _get_label(test_product,is_train = False)\n",
    "# 预处理标签\n",
    "\n",
    "train_sale['date'] = train_sale['year'].astype(str) + '-' + train_sale['month'].map(lambda x:'0'+str(x) if x<=9 else str(x))\n",
    "test_sale['date'] = test_sale['year'].astype(str) + '-' + test_sale['month'].map(lambda x:'0'+str(x) if x<=9 else str(x))\n",
    "# 处理日期特征，补0，目的是与product表日期对齐\n",
    "\n",
    "df_train = df_train_label.merge(train_sale, on = ['product_id','date'], how = 'left')\n",
    "df_test  = df_test_label.merge(test_sale, on = ['product_id','date'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d304f81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>date</th>\n",
       "      <th>label_sum</th>\n",
       "      <th>is_sale_day_sum</th>\n",
       "      <th>is_sale_day_count</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>order</th>\n",
       "      <th>start_stock</th>\n",
       "      <th>end_stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2018-02</td>\n",
       "      <td>517.0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>A1</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>2018-03</td>\n",
       "      <td>3190.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>A1</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>3568.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>2018-04</td>\n",
       "      <td>4186.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>A1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>4560.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>2018-05</td>\n",
       "      <td>5412.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>A1</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>7521.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>2018-06</td>\n",
       "      <td>5665.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>A1</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>7687.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id     date  label_sum  is_sale_day_sum  is_sale_day_count type  \\\n",
       "0        1001  2018-02      517.0                0                 28   A1   \n",
       "1        1001  2018-03     3190.0                0                 31   A1   \n",
       "2        1001  2018-04     4186.0                0                 30   A1   \n",
       "3        1001  2018-05     5412.0                0                 31   A1   \n",
       "4        1001  2018-06     5665.0                0                 30   A1   \n",
       "\n",
       "   year  month   order  start_stock  end_stock  \n",
       "0  2018      2  1129.0         47.0       70.0  \n",
       "1  2018      3  3568.0         70.0       91.0  \n",
       "2  2018      4  4560.0         91.0      110.0  \n",
       "3  2018      5  7521.0        110.0       47.0  \n",
       "4  2018      6  7687.0         47.0       41.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e41bd1fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>label_sum</th>\n",
       "      <th>is_sale_day_sum</th>\n",
       "      <th>is_sale_day_count</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>order</th>\n",
       "      <th>start_stock</th>\n",
       "      <th>end_stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7915.000000</td>\n",
       "      <td>7915.000000</td>\n",
       "      <td>7915.000000</td>\n",
       "      <td>7915.000000</td>\n",
       "      <td>7915.000000</td>\n",
       "      <td>7915.000000</td>\n",
       "      <td>7915.000000</td>\n",
       "      <td>7805.000000</td>\n",
       "      <td>7805.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1105.180417</td>\n",
       "      <td>2030.735692</td>\n",
       "      <td>5.752243</td>\n",
       "      <td>30.392167</td>\n",
       "      <td>2019.185723</td>\n",
       "      <td>6.290082</td>\n",
       "      <td>9164.604043</td>\n",
       "      <td>79.638181</td>\n",
       "      <td>83.206278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>60.770238</td>\n",
       "      <td>5740.358546</td>\n",
       "      <td>11.850776</td>\n",
       "      <td>0.904368</td>\n",
       "      <td>0.942294</td>\n",
       "      <td>3.478879</td>\n",
       "      <td>4469.659840</td>\n",
       "      <td>95.969136</td>\n",
       "      <td>96.789663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1001.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1101.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1053.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6769.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1105.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9310.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1158.000000</td>\n",
       "      <td>2278.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12677.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1210.000000</td>\n",
       "      <td>95780.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>17381.000000</td>\n",
       "      <td>2251.000000</td>\n",
       "      <td>2251.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        product_id     label_sum  is_sale_day_sum  is_sale_day_count  \\\n",
       "count  7915.000000   7915.000000      7915.000000        7915.000000   \n",
       "mean   1105.180417   2030.735692         5.752243          30.392167   \n",
       "std      60.770238   5740.358546        11.850776           0.904368   \n",
       "min    1001.000000      0.000000         0.000000          10.000000   \n",
       "25%    1053.000000      0.000000         0.000000          30.000000   \n",
       "50%    1105.000000      0.000000         0.000000          31.000000   \n",
       "75%    1158.000000   2278.000000         0.000000          31.000000   \n",
       "max    1210.000000  95780.000000        31.000000          31.000000   \n",
       "\n",
       "              year        month         order  start_stock    end_stock  \n",
       "count  7915.000000  7915.000000   7915.000000  7805.000000  7805.000000  \n",
       "mean   2019.185723     6.290082   9164.604043    79.638181    83.206278  \n",
       "std       0.942294     3.478879   4469.659840    95.969136    96.789663  \n",
       "min    2018.000000     1.000000   1101.000000    40.000000    40.000000  \n",
       "25%    2018.000000     3.000000   6769.000000    40.000000    40.000000  \n",
       "50%    2019.000000     6.000000   9310.000000    40.000000    40.000000  \n",
       "75%    2020.000000     9.000000  12677.000000    80.000000    87.000000  \n",
       "max    2021.000000    12.000000  17381.000000  2251.000000  2251.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b80efcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_sum</th>\n",
       "      <th>order</th>\n",
       "      <th>start_stock</th>\n",
       "      <th>end_stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label_sum</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236742</td>\n",
       "      <td>0.482234</td>\n",
       "      <td>0.493493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order</th>\n",
       "      <td>0.236742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014890</td>\n",
       "      <td>0.049593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_stock</th>\n",
       "      <td>0.482234</td>\n",
       "      <td>0.014890</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.692205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_stock</th>\n",
       "      <td>0.493493</td>\n",
       "      <td>0.049593</td>\n",
       "      <td>0.692205</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label_sum     order  start_stock  end_stock\n",
       "label_sum     1.000000  0.236742     0.482234   0.493493\n",
       "order         0.236742  1.000000     0.014890   0.049593\n",
       "start_stock   0.482234  0.014890     1.000000   0.692205\n",
       "end_stock     0.493493  0.049593     0.692205   1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - 50%的销量都为0，最大值最小值相差很大，考虑用np.log1p对预测目标数据缩放，使其分布趋向于正态分布\n",
    "df_train[['label_sum','order','start_stock', 'end_stock',]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9344d36",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'label_sum'}>,\n",
       "        <AxesSubplot:title={'center':'order'}>],\n",
       "       [<AxesSubplot:title={'center':'start_stock'}>,\n",
       "        <AxesSubplot:title={'center':'end_stock'}>]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train[['label_sum','order','start_stock', 'end_stock',]].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0758a59",
   "metadata": {},
   "source": [
    "#### 2、特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abac0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_feat(df, cols):\n",
    "    '''\n",
    "        输入：表df，待处理列cols\n",
    "        输出：添加scale特征后的新表\n",
    "    '''\n",
    "    for col in cols:\n",
    "        df[f'{col}_norm'] = (df[col] - df[col].min())/(df[col].max() - df[col].min())\n",
    "        # min-max归一化特征\n",
    "        df[f'{col}_log1p'] = np.log1p(df[col])\n",
    "        # log1p变换特征\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62ac6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_group_feat(df, stats = ['mean','max','min'], cols = ['month'], num_cols = ['order','start_stock','end_stock']):\n",
    "    '''\n",
    "        输入：表df，需要聚合的统计特征类型 stats，\n",
    "              聚合使用的类别特征列（一般为离散特征如商品类型）cols，\n",
    "              聚合的目标数值特征列 num_cols\n",
    "        输出：添加类别聚合特征后的新表\n",
    "    '''\n",
    "    for num_col in num_cols:\n",
    "        for feat in cols:\n",
    "            temp = df.groupby([feat]).agg({num_col:stats})\n",
    "            out_cols = []\n",
    "            out_cols.extend([f'{feat}_{num_col}_{s}' for s in stats])\n",
    "            temp.columns = out_cols\n",
    "            temp = temp.reset_index()\n",
    "\n",
    "            df = df.merge(temp, on=feat, how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e438e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFE(df, shift=0):\n",
    "    type_dict = {\"A1\":1,\"A2\":2,\"A3\":3}\n",
    "    df['type'] = df['type'].map(type_dict).values\n",
    "    season_dict = {\"1\":0,\"2\":0,\"3\":1,\"4\":1,\"5\":1,\"6\":2,\"7\":2,\"8\":2,\"9\":3,\"10\":3,\"11\":3,\"12\":0}\n",
    "    df['season'] = df['month'].map(season_dict).values\n",
    "    # 当月库存差\n",
    "    \n",
    "    \n",
    "##############################     0.5843300477317621        ################################\n",
    "    df['stock_diff'] = df['end_stock'] - df['start_stock']\n",
    "    df['stock_sum'] = df['end_stock'] + df['start_stock']\n",
    "    \n",
    "    # 类型的月的库存差量和\n",
    "    df[f'type_stock_diff_sum'] = df.groupby(['type','date'])[f'stock_diff'].transform('sum').values \n",
    "    # 商品id年库存差量和\n",
    "    df[f'product_year_stock_diff_sum'] = df.groupby(['product_id','year'])[f'stock_diff'].transform('sum').values  \n",
    "\n",
    "    # 当月所占历史数据（stock_diff）的比例\n",
    "    df[f'type_stock_diff_ratio'] = df[f'stock_diff'].values / df[f'type_stock_diff_sum'].values\n",
    "    df[f'product_year_stock_diff_ratio'] = df[f'stock_diff'].values / df[f'product_year_stock_diff_sum'].values\n",
    "\n",
    "    df[f'order_sale_ratio'] = (df[f'stock_diff']+1e-6)/(df[f'order']+1e-6)\n",
    "##############################     0.5843300477317621        ################################     \n",
    "\n",
    "##############################     0.7068198452363535        ################################        \n",
    "    # lag特征   \n",
    "    for i in range(1,4):\n",
    "        df[f'stock_diff_{i}']       = df.groupby('product_id')[f'stock_diff'].shift(i).values\n",
    "        df[f'stock_sum_{i}']       = df.groupby('product_id')[f'stock_sum'].shift(i).values\n",
    "        df[f'order_{i}']            = df.groupby('product_id')[f'order'].shift(i).values\n",
    "        df[f'start_stock_{i}']     = df.groupby('product_id')[f'start_stock'].shift(i).values\n",
    "        df[f'end_stock_{i}']       = df.groupby('product_id')[f'end_stock'].shift(i).values\n",
    "    \n",
    "    for i in range(1, 3-shift):\n",
    "        df[f'label_sum_{3-i}'] = df.groupby('product_id')[f'label_sum'].shift(3-i).values\n",
    "    \n",
    "    for i in [3,4,5]:\n",
    "        df[f'label_sum_{i}'] = df.groupby('product_id')[f'label_sum'].shift(i).values\n",
    "    \n",
    "    \n",
    "    df = add_group_feat(df, \n",
    "                      stats = ['mean'], \n",
    "                      cols = ['product_id'], \n",
    "                      num_cols = ['stock_diff'\n",
    "                                 ])\n",
    "    \n",
    "    df = add_group_feat(df, \n",
    "                  stats = ['mean'], \n",
    "                  cols = ['type'], \n",
    "                  num_cols = ['stock_diff'\n",
    "                             ])\n",
    "##############################     0.7068198452363535        ################################  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90b08007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train['time'] = (df_train.year-2018)*12+df_train.month\n",
    "df_test['time'] = (df_test.year-2018)*12+df_test.month\n",
    "# df = add_group_feat(df, \n",
    "#                   stats = ['mean', 'median', 'max', 'min', 'sum', 'skew'], \n",
    "#                   cols = ['month'], \n",
    "#                   num_cols = ['stock_diff',\n",
    "#                               'type_stock_diff_ratio',\n",
    "#                               'order_sale_ratio',\n",
    "#                               'order_sale_month_ratio',\n",
    "#                              ])\n",
    "\n",
    "# df_train = df[df['label_sum'].notna()].reset_index(drop=True)\n",
    "# df_test = df[df['label_sum'].isna()].reset_index(drop=True)\n",
    "\n",
    "def getFirstMonth(df):\n",
    "    simple = df[~df[\"label_sum\"].isna()]\n",
    "    simple = df[df[\"label_sum\"]>0]\n",
    "    # 获取第一次售卖的月份\n",
    "    simple[\"sale_first_month\"] = simple.groupby([\"product_id\"])[\"date\"].transform(\"first\")\n",
    "    simple = simple.loc[:, [\"product_id\", \"sale_first_month\"]].drop_duplicates()\n",
    "\n",
    "    df = df.merge(simple, on=[\"product_id\"], how=\"left\")\n",
    "    df['start_sale'] = (df['sale_first_month'] <= df['date']).astype('int')\n",
    "\n",
    "    # 过滤还未售卖的时间\n",
    "    df_first = df[df[\"sale_first_month\"] <= df[\"date\"]].reset_index(drop=True)\n",
    "\n",
    "    simple = df_first[~df_first[\"label_sum\"].isnull()]\n",
    "    simple[\"sale_month_count\"] = simple.groupby([\"product_id\"])[\"date\"].transform(\"count\")\n",
    "    simple = simple.loc[:, [\"product_id\", \"sale_month_count\"]].drop_duplicates()\n",
    "\n",
    "    df = df.merge(simple, on=[\"product_id\"], how=\"left\")\n",
    "    \n",
    "    del df['sale_first_month']\n",
    "#     del df['start_sale']\n",
    "    del df['sale_month_count']\n",
    "    return df\n",
    "\n",
    "def target_encode(df_train, df_test):\n",
    "    for col in ['product_id']:\n",
    "        for target in ['label_sum']:\n",
    "            for stat in ['mean']:\n",
    "                temp_dict = df_train[df_train.start_sale == 1].groupby([col])[target].agg([stat]).reset_index().rename(columns={stat: col+f'_target_{target}_{stat}'})\n",
    "                temp_dict.index = temp_dict[col].values\n",
    "                temp_dict = temp_dict[col+f'_target_{target}_{stat}'].to_dict()\n",
    "                df_train[col+f'_target_{target}_{stat}'] = df_train[col].map(temp_dict)\n",
    "                df_test[col+f'_target_{target}_{stat}']  = df_test[col].map(temp_dict)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba687001",
   "metadata": {},
   "source": [
    "#### 3、模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a941dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifly_metric(gt: np.array, pred: np.array) -> float:\n",
    "    preds = np.expm1(pred)\n",
    "    target = np.expm1(gt)\n",
    "    return np.sum( (1-np.abs(target-preds)*(1/(target+1e-9))) * (target/(np.sum(target)+1e-9)))\n",
    "\n",
    "def lgb_ifly_metric(pred, gt):\n",
    "    \"\"\"The competition metric with lightgbm's calling convention\"\"\"\n",
    "    return ('ifly',\n",
    "            ifly_metric(gt.get_label(), pred),\n",
    "            True)\n",
    "\n",
    "def evalScore(train_df, oof):    \n",
    "    df = train_df.copy()\n",
    "    df['label_sum'] = np.expm1(df['label_sum'])\n",
    "    df['target_weight'] = df['label_sum'] / df.groupby(['year', 'month'])['label_sum'].transform('sum')\n",
    "\n",
    "    df['oof'] = np.expm1(oof)\n",
    "    score1 = np.sum((1 - np.abs(df['label_sum']-df['oof']) / (df['label_sum'])\n",
    "                     ) *\n",
    "                    df['target_weight']) / 5\n",
    "    return score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eb6dcca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6773\n",
      "[LightGBM] [Info] Number of data points in the train set: 7706, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.159931\tvalid_1's l1: 0.714115\n",
      "[1000]\ttraining's l1: 0.153402\tvalid_1's l1: 0.702889\n",
      "[1500]\ttraining's l1: 0.151033\tvalid_1's l1: 0.701383\n",
      "[2000]\ttraining's l1: 0.142674\tvalid_1's l1: 0.688233\n",
      "[2500]\ttraining's l1: 0.138583\tvalid_1's l1: 0.682844\n",
      "[3000]\ttraining's l1: 0.136824\tvalid_1's l1: 0.67918\n",
      "[3500]\ttraining's l1: 0.13511\tvalid_1's l1: 0.677511\n",
      "[4000]\ttraining's l1: 0.134208\tvalid_1's l1: 0.676581\n",
      "Early stopping, best iteration is:\n",
      "[3860]\ttraining's l1: 0.134418\tvalid_1's l1: 0.676389\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6758\n",
      "[LightGBM] [Info] Number of data points in the train set: 7497, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.157874\tvalid_1's l1: 0.843877\n",
      "[1000]\ttraining's l1: 0.155288\tvalid_1's l1: 0.826832\n",
      "[1500]\ttraining's l1: 0.149096\tvalid_1's l1: 0.826542\n",
      "[2000]\ttraining's l1: 0.139058\tvalid_1's l1: 0.822625\n",
      "[2500]\ttraining's l1: 0.13417\tvalid_1's l1: 0.823697\n",
      "Early stopping, best iteration is:\n",
      "[2451]\ttraining's l1: 0.134508\tvalid_1's l1: 0.822271\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6747\n",
      "[LightGBM] [Info] Number of data points in the train set: 7288, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.158597\tvalid_1's l1: 0.43873\n",
      "[1000]\ttraining's l1: 0.156884\tvalid_1's l1: 0.437277\n",
      "[1500]\ttraining's l1: 0.152323\tvalid_1's l1: 0.434884\n",
      "[2000]\ttraining's l1: 0.143083\tvalid_1's l1: 0.431445\n",
      "[2500]\ttraining's l1: 0.136176\tvalid_1's l1: 0.43232\n",
      "[3000]\ttraining's l1: 0.132453\tvalid_1's l1: 0.429992\n",
      "Early stopping, best iteration is:\n",
      "[2684]\ttraining's l1: 0.134358\tvalid_1's l1: 0.429678\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6740\n",
      "[LightGBM] [Info] Number of data points in the train set: 7079, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.155065\tvalid_1's l1: 0.423821\n",
      "[1000]\ttraining's l1: 0.153253\tvalid_1's l1: 0.422176\n",
      "[1500]\ttraining's l1: 0.149611\tvalid_1's l1: 0.418748\n",
      "[2000]\ttraining's l1: 0.142348\tvalid_1's l1: 0.414917\n",
      "[2500]\ttraining's l1: 0.135428\tvalid_1's l1: 0.41169\n",
      "[3000]\ttraining's l1: 0.132062\tvalid_1's l1: 0.411098\n",
      "[3500]\ttraining's l1: 0.130323\tvalid_1's l1: 0.411058\n",
      "Early stopping, best iteration is:\n",
      "[3224]\ttraining's l1: 0.131302\tvalid_1's l1: 0.410982\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6731\n",
      "[LightGBM] [Info] Number of data points in the train set: 6870, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.14361\tvalid_1's l1: 0.36094\n",
      "[1000]\ttraining's l1: 0.131029\tvalid_1's l1: 0.354234\n",
      "[1500]\ttraining's l1: 0.127597\tvalid_1's l1: 0.352195\n",
      "[2000]\ttraining's l1: 0.125288\tvalid_1's l1: 0.352564\n",
      "Early stopping, best iteration is:\n",
      "[1657]\ttraining's l1: 0.126846\tvalid_1's l1: 0.351755\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6518\n",
      "[LightGBM] [Info] Number of data points in the train set: 7706, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.177887\tvalid_1's l1: 0.403767\n",
      "[1000]\ttraining's l1: 0.175659\tvalid_1's l1: 0.401544\n",
      "[1500]\ttraining's l1: 0.169054\tvalid_1's l1: 0.401052\n",
      "Early stopping, best iteration is:\n",
      "[1103]\ttraining's l1: 0.174675\tvalid_1's l1: 0.40051\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6503\n",
      "[LightGBM] [Info] Number of data points in the train set: 7497, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.1762\tvalid_1's l1: 1.14461\n",
      "Early stopping, best iteration is:\n",
      "[355]\ttraining's l1: 0.182018\tvalid_1's l1: 1.13805\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6492\n",
      "[LightGBM] [Info] Number of data points in the train set: 7288, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.169232\tvalid_1's l1: 0.459751\n",
      "[1000]\ttraining's l1: 0.16549\tvalid_1's l1: 0.459107\n",
      "[1500]\ttraining's l1: 0.155851\tvalid_1's l1: 0.453163\n",
      "[2000]\ttraining's l1: 0.148755\tvalid_1's l1: 0.450737\n",
      "[2500]\ttraining's l1: 0.144343\tvalid_1's l1: 0.450779\n",
      "Early stopping, best iteration is:\n",
      "[2095]\ttraining's l1: 0.14791\tvalid_1's l1: 0.449682\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6485\n",
      "[LightGBM] [Info] Number of data points in the train set: 7079, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.170635\tvalid_1's l1: 0.488626\n",
      "[1000]\ttraining's l1: 0.168634\tvalid_1's l1: 0.484913\n",
      "[1500]\ttraining's l1: 0.161797\tvalid_1's l1: 0.476966\n",
      "[2000]\ttraining's l1: 0.150636\tvalid_1's l1: 0.46842\n",
      "[2500]\ttraining's l1: 0.145004\tvalid_1's l1: 0.466353\n",
      "[3000]\ttraining's l1: 0.143035\tvalid_1's l1: 0.466233\n",
      "Early stopping, best iteration is:\n",
      "[2829]\ttraining's l1: 0.143522\tvalid_1's l1: 0.465764\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6476\n",
      "[LightGBM] [Info] Number of data points in the train set: 6870, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.161924\tvalid_1's l1: 0.480452\n",
      "[1000]\ttraining's l1: 0.160307\tvalid_1's l1: 0.4795\n",
      "[1500]\ttraining's l1: 0.15594\tvalid_1's l1: 0.476022\n",
      "[2000]\ttraining's l1: 0.146103\tvalid_1's l1: 0.468263\n",
      "[2500]\ttraining's l1: 0.139559\tvalid_1's l1: 0.463278\n",
      "[3000]\ttraining's l1: 0.137248\tvalid_1's l1: 0.462796\n",
      "[3500]\ttraining's l1: 0.135635\tvalid_1's l1: 0.462405\n",
      "[4000]\ttraining's l1: 0.134287\tvalid_1's l1: 0.462039\n",
      "[4500]\ttraining's l1: 0.133338\tvalid_1's l1: 0.461499\n",
      "[5000]\ttraining's l1: 0.13255\tvalid_1's l1: 0.461231\n",
      "[5500]\ttraining's l1: 0.131897\tvalid_1's l1: 0.461034\n",
      "[6000]\ttraining's l1: 0.13134\tvalid_1's l1: 0.460746\n",
      "[6500]\ttraining's l1: 0.130624\tvalid_1's l1: 0.460346\n",
      "[7000]\ttraining's l1: 0.130185\tvalid_1's l1: 0.459667\n",
      "[7500]\ttraining's l1: 0.129667\tvalid_1's l1: 0.460198\n",
      "Early stopping, best iteration is:\n",
      "[7144]\ttraining's l1: 0.130045\tvalid_1's l1: 0.459552\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6263\n",
      "[LightGBM] [Info] Number of data points in the train set: 7706, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.18991\tvalid_1's l1: 0.390023\n",
      "[1000]\ttraining's l1: 0.185251\tvalid_1's l1: 0.383223\n",
      "[1500]\ttraining's l1: 0.170398\tvalid_1's l1: 0.371603\n",
      "[2000]\ttraining's l1: 0.161253\tvalid_1's l1: 0.36571\n",
      "[2500]\ttraining's l1: 0.155664\tvalid_1's l1: 0.365004\n",
      "[3000]\ttraining's l1: 0.153472\tvalid_1's l1: 0.364658\n",
      "Early stopping, best iteration is:\n",
      "[2884]\ttraining's l1: 0.153929\tvalid_1's l1: 0.364041\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6248\n",
      "[LightGBM] [Info] Number of data points in the train set: 7497, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.184053\tvalid_1's l1: 1.11707\n",
      "[1000]\ttraining's l1: 0.179425\tvalid_1's l1: 1.10497\n",
      "[1500]\ttraining's l1: 0.170293\tvalid_1's l1: 1.10182\n",
      "[2000]\ttraining's l1: 0.159136\tvalid_1's l1: 1.0915\n",
      "Early stopping, best iteration is:\n",
      "[1964]\ttraining's l1: 0.159759\tvalid_1's l1: 1.09089\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6237\n",
      "[LightGBM] [Info] Number of data points in the train set: 7288, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.176946\tvalid_1's l1: 0.527464\n",
      "[1000]\ttraining's l1: 0.172219\tvalid_1's l1: 0.527612\n",
      "[1500]\ttraining's l1: 0.157148\tvalid_1's l1: 0.524171\n",
      "[2000]\ttraining's l1: 0.14738\tvalid_1's l1: 0.521907\n",
      "[2500]\ttraining's l1: 0.142252\tvalid_1's l1: 0.519749\n",
      "[3000]\ttraining's l1: 0.139046\tvalid_1's l1: 0.518462\n",
      "[3500]\ttraining's l1: 0.137414\tvalid_1's l1: 0.517968\n",
      "[4000]\ttraining's l1: 0.13612\tvalid_1's l1: 0.51782\n",
      "Early stopping, best iteration is:\n",
      "[3788]\ttraining's l1: 0.136492\tvalid_1's l1: 0.517635\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6230\n",
      "[LightGBM] [Info] Number of data points in the train set: 7079, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.177379\tvalid_1's l1: 0.500066\n",
      "[1000]\ttraining's l1: 0.17103\tvalid_1's l1: 0.494341\n",
      "[1500]\ttraining's l1: 0.160849\tvalid_1's l1: 0.486064\n",
      "[2000]\ttraining's l1: 0.15231\tvalid_1's l1: 0.482902\n",
      "[2500]\ttraining's l1: 0.147463\tvalid_1's l1: 0.48109\n",
      "[3000]\ttraining's l1: 0.144017\tvalid_1's l1: 0.480629\n",
      "[3500]\ttraining's l1: 0.142251\tvalid_1's l1: 0.479795\n",
      "[4000]\ttraining's l1: 0.140263\tvalid_1's l1: 0.478309\n",
      "[4500]\ttraining's l1: 0.138292\tvalid_1's l1: 0.475195\n",
      "[5000]\ttraining's l1: 0.137526\tvalid_1's l1: 0.475517\n",
      "Early stopping, best iteration is:\n",
      "[4553]\ttraining's l1: 0.138213\tvalid_1's l1: 0.475194\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6221\n",
      "[LightGBM] [Info] Number of data points in the train set: 6870, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.179088\tvalid_1's l1: 0.443364\n",
      "[1000]\ttraining's l1: 0.171617\tvalid_1's l1: 0.437815\n",
      "[1500]\ttraining's l1: 0.160488\tvalid_1's l1: 0.431821\n",
      "[2000]\ttraining's l1: 0.150046\tvalid_1's l1: 0.425461\n",
      "[2500]\ttraining's l1: 0.145702\tvalid_1's l1: 0.423584\n",
      "[3000]\ttraining's l1: 0.142207\tvalid_1's l1: 0.419682\n",
      "[3500]\ttraining's l1: 0.13991\tvalid_1's l1: 0.419115\n",
      "[4000]\ttraining's l1: 0.13833\tvalid_1's l1: 0.419103\n",
      "Early stopping, best iteration is:\n",
      "[3734]\ttraining's l1: 0.139113\tvalid_1's l1: 0.418774\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6773\n",
      "[LightGBM] [Info] Number of data points in the train set: 7706, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.1679\tvalid_1's l1: 0.767738\n",
      "[1000]\ttraining's l1: 0.166441\tvalid_1's l1: 0.762615\n",
      "[1500]\ttraining's l1: 0.160543\tvalid_1's l1: 0.751377\n",
      "[2000]\ttraining's l1: 0.152105\tvalid_1's l1: 0.743543\n",
      "[2500]\ttraining's l1: 0.145385\tvalid_1's l1: 0.733314\n",
      "[3000]\ttraining's l1: 0.140495\tvalid_1's l1: 0.724021\n",
      "[3500]\ttraining's l1: 0.138714\tvalid_1's l1: 0.719637\n",
      "[4000]\ttraining's l1: 0.137068\tvalid_1's l1: 0.717427\n",
      "[4500]\ttraining's l1: 0.135563\tvalid_1's l1: 0.717719\n",
      "Early stopping, best iteration is:\n",
      "[4164]\ttraining's l1: 0.136339\tvalid_1's l1: 0.716712\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6758\n",
      "[LightGBM] [Info] Number of data points in the train set: 7497, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.156316\tvalid_1's l1: 0.868704\n",
      "Early stopping, best iteration is:\n",
      "[471]\ttraining's l1: 0.156873\tvalid_1's l1: 0.866285\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6747\n",
      "[LightGBM] [Info] Number of data points in the train set: 7288, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.158468\tvalid_1's l1: 0.456468\n",
      "[1000]\ttraining's l1: 0.154973\tvalid_1's l1: 0.454799\n",
      "[1500]\ttraining's l1: 0.148778\tvalid_1's l1: 0.452231\n",
      "[2000]\ttraining's l1: 0.141713\tvalid_1's l1: 0.450817\n",
      "[2500]\ttraining's l1: 0.135375\tvalid_1's l1: 0.451085\n",
      "Early stopping, best iteration is:\n",
      "[2182]\ttraining's l1: 0.139458\tvalid_1's l1: 0.449936\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6740\n",
      "[LightGBM] [Info] Number of data points in the train set: 7079, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.149324\tvalid_1's l1: 0.429533\n",
      "[1000]\ttraining's l1: 0.136366\tvalid_1's l1: 0.422011\n",
      "[1500]\ttraining's l1: 0.134362\tvalid_1's l1: 0.422167\n",
      "[2000]\ttraining's l1: 0.130439\tvalid_1's l1: 0.421419\n",
      "[2500]\ttraining's l1: 0.127519\tvalid_1's l1: 0.421372\n",
      "Early stopping, best iteration is:\n",
      "[2403]\ttraining's l1: 0.128195\tvalid_1's l1: 0.421137\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6731\n",
      "[LightGBM] [Info] Number of data points in the train set: 6870, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.150287\tvalid_1's l1: 0.387279\n",
      "[1000]\ttraining's l1: 0.148796\tvalid_1's l1: 0.386152\n",
      "[1500]\ttraining's l1: 0.143393\tvalid_1's l1: 0.379306\n",
      "[2000]\ttraining's l1: 0.136206\tvalid_1's l1: 0.373701\n",
      "[2500]\ttraining's l1: 0.130957\tvalid_1's l1: 0.371714\n",
      "[3000]\ttraining's l1: 0.129153\tvalid_1's l1: 0.370944\n",
      "[3500]\ttraining's l1: 0.128058\tvalid_1's l1: 0.37074\n",
      "[4000]\ttraining's l1: 0.12711\tvalid_1's l1: 0.370403\n",
      "[4500]\ttraining's l1: 0.126329\tvalid_1's l1: 0.36957\n",
      "[5000]\ttraining's l1: 0.125695\tvalid_1's l1: 0.369316\n",
      "[5500]\ttraining's l1: 0.124913\tvalid_1's l1: 0.369039\n",
      "[6000]\ttraining's l1: 0.124189\tvalid_1's l1: 0.367828\n",
      "[6500]\ttraining's l1: 0.122519\tvalid_1's l1: 0.350558\n",
      "[7000]\ttraining's l1: 0.122053\tvalid_1's l1: 0.350229\n",
      "[7500]\ttraining's l1: 0.121539\tvalid_1's l1: 0.349697\n",
      "[8000]\ttraining's l1: 0.121042\tvalid_1's l1: 0.349648\n",
      "[8500]\ttraining's l1: 0.120593\tvalid_1's l1: 0.349101\n",
      "[9000]\ttraining's l1: 0.120122\tvalid_1's l1: 0.34894\n",
      "[9500]\ttraining's l1: 0.119705\tvalid_1's l1: 0.348868\n",
      "Early stopping, best iteration is:\n",
      "[9222]\ttraining's l1: 0.119911\tvalid_1's l1: 0.348757\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6518\n",
      "[LightGBM] [Info] Number of data points in the train set: 7706, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.180806\tvalid_1's l1: 0.426505\n",
      "[1000]\ttraining's l1: 0.178032\tvalid_1's l1: 0.422402\n",
      "[1500]\ttraining's l1: 0.16755\tvalid_1's l1: 0.416621\n",
      "[2000]\ttraining's l1: 0.161438\tvalid_1's l1: 0.414131\n",
      "[2500]\ttraining's l1: 0.156815\tvalid_1's l1: 0.412175\n",
      "[3000]\ttraining's l1: 0.153714\tvalid_1's l1: 0.412198\n",
      "Early stopping, best iteration is:\n",
      "[2618]\ttraining's l1: 0.155916\tvalid_1's l1: 0.411904\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6503\n",
      "[LightGBM] [Info] Number of data points in the train set: 7497, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.186797\tvalid_1's l1: 1.1626\n",
      "Early stopping, best iteration is:\n",
      "[366]\ttraining's l1: 0.189594\tvalid_1's l1: 1.16175\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6492\n",
      "[LightGBM] [Info] Number of data points in the train set: 7288, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.163431\tvalid_1's l1: 0.479377\n",
      "[1000]\ttraining's l1: 0.161705\tvalid_1's l1: 0.477484\n",
      "[1500]\ttraining's l1: 0.153072\tvalid_1's l1: 0.47523\n",
      "[2000]\ttraining's l1: 0.145754\tvalid_1's l1: 0.471891\n",
      "[2500]\ttraining's l1: 0.141303\tvalid_1's l1: 0.470696\n",
      "[3000]\ttraining's l1: 0.13758\tvalid_1's l1: 0.469799\n",
      "Early stopping, best iteration is:\n",
      "[2956]\ttraining's l1: 0.137715\tvalid_1's l1: 0.469634\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6485\n",
      "[LightGBM] [Info] Number of data points in the train set: 7079, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.170342\tvalid_1's l1: 0.412963\n",
      "[1000]\ttraining's l1: 0.166542\tvalid_1's l1: 0.406434\n",
      "[1500]\ttraining's l1: 0.155971\tvalid_1's l1: 0.394621\n",
      "[2000]\ttraining's l1: 0.148094\tvalid_1's l1: 0.389426\n",
      "[2500]\ttraining's l1: 0.142332\tvalid_1's l1: 0.385908\n",
      "[3000]\ttraining's l1: 0.140213\tvalid_1's l1: 0.38523\n",
      "[3500]\ttraining's l1: 0.138019\tvalid_1's l1: 0.385357\n",
      "Early stopping, best iteration is:\n",
      "[3341]\ttraining's l1: 0.13859\tvalid_1's l1: 0.384516\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6476\n",
      "[LightGBM] [Info] Number of data points in the train set: 6870, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.164965\tvalid_1's l1: 0.501028\n",
      "[1000]\ttraining's l1: 0.162565\tvalid_1's l1: 0.49758\n",
      "[1500]\ttraining's l1: 0.15582\tvalid_1's l1: 0.491058\n",
      "[2000]\ttraining's l1: 0.148634\tvalid_1's l1: 0.485949\n",
      "[2500]\ttraining's l1: 0.141613\tvalid_1's l1: 0.479843\n",
      "[3000]\ttraining's l1: 0.138454\tvalid_1's l1: 0.478717\n",
      "[3500]\ttraining's l1: 0.136584\tvalid_1's l1: 0.478452\n",
      "[4000]\ttraining's l1: 0.135499\tvalid_1's l1: 0.478442\n",
      "[4500]\ttraining's l1: 0.134345\tvalid_1's l1: 0.477893\n",
      "[5000]\ttraining's l1: 0.132916\tvalid_1's l1: 0.476575\n",
      "[5500]\ttraining's l1: 0.131571\tvalid_1's l1: 0.476292\n",
      "[6000]\ttraining's l1: 0.130964\tvalid_1's l1: 0.476182\n",
      "[6500]\ttraining's l1: 0.130005\tvalid_1's l1: 0.475764\n",
      "[7000]\ttraining's l1: 0.128773\tvalid_1's l1: 0.474496\n",
      "[7500]\ttraining's l1: 0.128302\tvalid_1's l1: 0.474212\n",
      "[8000]\ttraining's l1: 0.127584\tvalid_1's l1: 0.473879\n",
      "Early stopping, best iteration is:\n",
      "[7741]\ttraining's l1: 0.127903\tvalid_1's l1: 0.473847\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6263\n",
      "[LightGBM] [Info] Number of data points in the train set: 7706, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.189684\tvalid_1's l1: 0.360407\n",
      "[1000]\ttraining's l1: 0.185697\tvalid_1's l1: 0.353954\n",
      "[1500]\ttraining's l1: 0.177902\tvalid_1's l1: 0.344957\n",
      "[2000]\ttraining's l1: 0.167116\tvalid_1's l1: 0.337083\n",
      "[2500]\ttraining's l1: 0.161077\tvalid_1's l1: 0.335455\n",
      "[3000]\ttraining's l1: 0.157886\tvalid_1's l1: 0.335546\n",
      "[3500]\ttraining's l1: 0.156247\tvalid_1's l1: 0.332966\n",
      "[4000]\ttraining's l1: 0.154769\tvalid_1's l1: 0.332743\n",
      "Early stopping, best iteration is:\n",
      "[3881]\ttraining's l1: 0.155123\tvalid_1's l1: 0.332138\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6248\n",
      "[LightGBM] [Info] Number of data points in the train set: 7497, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.184692\tvalid_1's l1: 1.1167\n",
      "[1000]\ttraining's l1: 0.178673\tvalid_1's l1: 1.11359\n",
      "[1500]\ttraining's l1: 0.165714\tvalid_1's l1: 1.09947\n",
      "[2000]\ttraining's l1: 0.15485\tvalid_1's l1: 1.09356\n",
      "[2500]\ttraining's l1: 0.150807\tvalid_1's l1: 1.09238\n",
      "[3000]\ttraining's l1: 0.148891\tvalid_1's l1: 1.09207\n",
      "[3500]\ttraining's l1: 0.147359\tvalid_1's l1: 1.092\n",
      "Early stopping, best iteration is:\n",
      "[3263]\ttraining's l1: 0.147941\tvalid_1's l1: 1.09126\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6237\n",
      "[LightGBM] [Info] Number of data points in the train set: 7288, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.173267\tvalid_1's l1: 0.509029\n",
      "[1000]\ttraining's l1: 0.170055\tvalid_1's l1: 0.506635\n",
      "[1500]\ttraining's l1: 0.161548\tvalid_1's l1: 0.505228\n",
      "[2000]\ttraining's l1: 0.152863\tvalid_1's l1: 0.501503\n",
      "[2500]\ttraining's l1: 0.147716\tvalid_1's l1: 0.501023\n",
      "Early stopping, best iteration is:\n",
      "[2236]\ttraining's l1: 0.149418\tvalid_1's l1: 0.500184\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6230\n",
      "[LightGBM] [Info] Number of data points in the train set: 7079, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.171374\tvalid_1's l1: 0.493096\n",
      "[1000]\ttraining's l1: 0.166711\tvalid_1's l1: 0.490268\n",
      "[1500]\ttraining's l1: 0.157037\tvalid_1's l1: 0.482288\n",
      "[2000]\ttraining's l1: 0.147952\tvalid_1's l1: 0.474053\n",
      "[2500]\ttraining's l1: 0.143464\tvalid_1's l1: 0.471822\n",
      "[3000]\ttraining's l1: 0.140861\tvalid_1's l1: 0.469026\n",
      "Early stopping, best iteration is:\n",
      "[2906]\ttraining's l1: 0.141155\tvalid_1's l1: 0.468963\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6221\n",
      "[LightGBM] [Info] Number of data points in the train set: 6870, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.170266\tvalid_1's l1: 0.435857\n",
      "[1000]\ttraining's l1: 0.165644\tvalid_1's l1: 0.434259\n",
      "[1500]\ttraining's l1: 0.153884\tvalid_1's l1: 0.428038\n",
      "[2000]\ttraining's l1: 0.146635\tvalid_1's l1: 0.423726\n",
      "[2500]\ttraining's l1: 0.14368\tvalid_1's l1: 0.42301\n",
      "Early stopping, best iteration is:\n",
      "[2470]\ttraining's l1: 0.143824\tvalid_1's l1: 0.422934\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6773\n",
      "[LightGBM] [Info] Number of data points in the train set: 7706, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.169031\tvalid_1's l1: 0.859624\n",
      "[1000]\ttraining's l1: 0.166308\tvalid_1's l1: 0.851599\n",
      "[1500]\ttraining's l1: 0.157469\tvalid_1's l1: 0.832283\n",
      "[2000]\ttraining's l1: 0.149483\tvalid_1's l1: 0.826724\n",
      "[2500]\ttraining's l1: 0.144141\tvalid_1's l1: 0.820419\n",
      "[3000]\ttraining's l1: 0.141519\tvalid_1's l1: 0.815727\n",
      "[3500]\ttraining's l1: 0.140454\tvalid_1's l1: 0.815005\n",
      "[4000]\ttraining's l1: 0.13939\tvalid_1's l1: 0.813588\n",
      "[4500]\ttraining's l1: 0.138694\tvalid_1's l1: 0.81371\n",
      "[5000]\ttraining's l1: 0.13805\tvalid_1's l1: 0.812966\n",
      "Early stopping, best iteration is:\n",
      "[4895]\ttraining's l1: 0.138246\tvalid_1's l1: 0.812499\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6758\n",
      "[LightGBM] [Info] Number of data points in the train set: 7497, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.161247\tvalid_1's l1: 0.829092\n",
      "[1000]\ttraining's l1: 0.157526\tvalid_1's l1: 0.820568\n",
      "[1500]\ttraining's l1: 0.148374\tvalid_1's l1: 0.80785\n",
      "[2000]\ttraining's l1: 0.139121\tvalid_1's l1: 0.787012\n",
      "[2500]\ttraining's l1: 0.135489\tvalid_1's l1: 0.78587\n",
      "Early stopping, best iteration is:\n",
      "[2273]\ttraining's l1: 0.136679\tvalid_1's l1: 0.783571\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6747\n",
      "[LightGBM] [Info] Number of data points in the train set: 7288, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.156613\tvalid_1's l1: 0.446508\n",
      "[1000]\ttraining's l1: 0.153569\tvalid_1's l1: 0.444374\n",
      "[1500]\ttraining's l1: 0.145104\tvalid_1's l1: 0.441906\n",
      "[2000]\ttraining's l1: 0.137462\tvalid_1's l1: 0.441807\n",
      "[2500]\ttraining's l1: 0.133403\tvalid_1's l1: 0.442023\n",
      "Early stopping, best iteration is:\n",
      "[2046]\ttraining's l1: 0.137126\tvalid_1's l1: 0.441534\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6740\n",
      "[LightGBM] [Info] Number of data points in the train set: 7079, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.149931\tvalid_1's l1: 0.436596\n",
      "[1000]\ttraining's l1: 0.146137\tvalid_1's l1: 0.433337\n",
      "[1500]\ttraining's l1: 0.140239\tvalid_1's l1: 0.428301\n",
      "[2000]\ttraining's l1: 0.1341\tvalid_1's l1: 0.426018\n",
      "Early stopping, best iteration is:\n",
      "[1653]\ttraining's l1: 0.136753\tvalid_1's l1: 0.425444\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6731\n",
      "[LightGBM] [Info] Number of data points in the train set: 6870, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.152396\tvalid_1's l1: 0.368741\n",
      "[1000]\ttraining's l1: 0.149403\tvalid_1's l1: 0.365629\n",
      "[1500]\ttraining's l1: 0.146873\tvalid_1's l1: 0.362027\n",
      "[2000]\ttraining's l1: 0.138311\tvalid_1's l1: 0.356194\n",
      "[2500]\ttraining's l1: 0.134682\tvalid_1's l1: 0.353724\n",
      "[3000]\ttraining's l1: 0.132074\tvalid_1's l1: 0.352601\n",
      "[3500]\ttraining's l1: 0.130051\tvalid_1's l1: 0.351677\n",
      "[4000]\ttraining's l1: 0.128684\tvalid_1's l1: 0.349615\n",
      "[4500]\ttraining's l1: 0.127644\tvalid_1's l1: 0.344383\n",
      "[5000]\ttraining's l1: 0.126166\tvalid_1's l1: 0.339116\n",
      "Early stopping, best iteration is:\n",
      "[4676]\ttraining's l1: 0.126756\tvalid_1's l1: 0.338778\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6518\n",
      "[LightGBM] [Info] Number of data points in the train set: 7706, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.18159\tvalid_1's l1: 0.455889\n",
      "[1000]\ttraining's l1: 0.178021\tvalid_1's l1: 0.452437\n",
      "[1500]\ttraining's l1: 0.169023\tvalid_1's l1: 0.443636\n",
      "[2000]\ttraining's l1: 0.16161\tvalid_1's l1: 0.436744\n",
      "[2500]\ttraining's l1: 0.157147\tvalid_1's l1: 0.433954\n",
      "[3000]\ttraining's l1: 0.152734\tvalid_1's l1: 0.433713\n",
      "Early stopping, best iteration is:\n",
      "[2907]\ttraining's l1: 0.153459\tvalid_1's l1: 0.433111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6503\n",
      "[LightGBM] [Info] Number of data points in the train set: 7497, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.171885\tvalid_1's l1: 1.09043\n",
      "Early stopping, best iteration is:\n",
      "[402]\ttraining's l1: 0.175744\tvalid_1's l1: 1.08538\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6492\n",
      "[LightGBM] [Info] Number of data points in the train set: 7288, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.166825\tvalid_1's l1: 0.481371\n",
      "[1000]\ttraining's l1: 0.163586\tvalid_1's l1: 0.478066\n",
      "[1500]\ttraining's l1: 0.154824\tvalid_1's l1: 0.475261\n",
      "[2000]\ttraining's l1: 0.145651\tvalid_1's l1: 0.47365\n",
      "Early stopping, best iteration is:\n",
      "[1665]\ttraining's l1: 0.151556\tvalid_1's l1: 0.472867\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6485\n",
      "[LightGBM] [Info] Number of data points in the train set: 7079, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.176825\tvalid_1's l1: 0.478072\n",
      "[1000]\ttraining's l1: 0.173556\tvalid_1's l1: 0.475305\n",
      "[1500]\ttraining's l1: 0.165058\tvalid_1's l1: 0.469372\n",
      "[2000]\ttraining's l1: 0.154203\tvalid_1's l1: 0.461429\n",
      "[2500]\ttraining's l1: 0.148428\tvalid_1's l1: 0.458784\n",
      "Early stopping, best iteration is:\n",
      "[2449]\ttraining's l1: 0.149181\tvalid_1's l1: 0.458654\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6476\n",
      "[LightGBM] [Info] Number of data points in the train set: 6870, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.161641\tvalid_1's l1: 0.477956\n",
      "[1000]\ttraining's l1: 0.15812\tvalid_1's l1: 0.473221\n",
      "[1500]\ttraining's l1: 0.150028\tvalid_1's l1: 0.468912\n",
      "[2000]\ttraining's l1: 0.143658\tvalid_1's l1: 0.46424\n",
      "[2500]\ttraining's l1: 0.139061\tvalid_1's l1: 0.463567\n",
      "[3000]\ttraining's l1: 0.137101\tvalid_1's l1: 0.462939\n",
      "[3500]\ttraining's l1: 0.135662\tvalid_1's l1: 0.462733\n",
      "[4000]\ttraining's l1: 0.134584\tvalid_1's l1: 0.46271\n",
      "[4500]\ttraining's l1: 0.133391\tvalid_1's l1: 0.462105\n",
      "Early stopping, best iteration is:\n",
      "[4179]\ttraining's l1: 0.134073\tvalid_1's l1: 0.461985\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6263\n",
      "[LightGBM] [Info] Number of data points in the train set: 7706, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.18994\tvalid_1's l1: 0.376959\n",
      "[1000]\ttraining's l1: 0.18451\tvalid_1's l1: 0.373696\n",
      "[1500]\ttraining's l1: 0.177181\tvalid_1's l1: 0.36777\n",
      "[2000]\ttraining's l1: 0.167176\tvalid_1's l1: 0.362982\n",
      "[2500]\ttraining's l1: 0.161315\tvalid_1's l1: 0.358044\n",
      "[3000]\ttraining's l1: 0.158453\tvalid_1's l1: 0.357187\n",
      "[3500]\ttraining's l1: 0.15678\tvalid_1's l1: 0.356639\n",
      "[4000]\ttraining's l1: 0.155343\tvalid_1's l1: 0.356747\n",
      "Early stopping, best iteration is:\n",
      "[3562]\ttraining's l1: 0.156522\tvalid_1's l1: 0.356571\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6248\n",
      "[LightGBM] [Info] Number of data points in the train set: 7497, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.188049\tvalid_1's l1: 1.11886\n",
      "Early stopping, best iteration is:\n",
      "[379]\ttraining's l1: 0.191414\tvalid_1's l1: 1.11581\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6237\n",
      "[LightGBM] [Info] Number of data points in the train set: 7288, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.175521\tvalid_1's l1: 0.548413\n",
      "Early stopping, best iteration is:\n",
      "[371]\ttraining's l1: 0.181416\tvalid_1's l1: 0.547229\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6230\n",
      "[LightGBM] [Info] Number of data points in the train set: 7079, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.174478\tvalid_1's l1: 0.499539\n",
      "[1000]\ttraining's l1: 0.170831\tvalid_1's l1: 0.495698\n",
      "[1500]\ttraining's l1: 0.160149\tvalid_1's l1: 0.484536\n",
      "[2000]\ttraining's l1: 0.150701\tvalid_1's l1: 0.480471\n",
      "[2500]\ttraining's l1: 0.145245\tvalid_1's l1: 0.478867\n",
      "[3000]\ttraining's l1: 0.141915\tvalid_1's l1: 0.47817\n",
      "[3500]\ttraining's l1: 0.140092\tvalid_1's l1: 0.477866\n",
      "Early stopping, best iteration is:\n",
      "[3249]\ttraining's l1: 0.140879\tvalid_1's l1: 0.477774\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6221\n",
      "[LightGBM] [Info] Number of data points in the train set: 6870, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.166936\tvalid_1's l1: 0.424096\n",
      "[1000]\ttraining's l1: 0.164128\tvalid_1's l1: 0.421725\n",
      "[1500]\ttraining's l1: 0.158622\tvalid_1's l1: 0.417093\n",
      "[2000]\ttraining's l1: 0.151156\tvalid_1's l1: 0.413991\n",
      "[2500]\ttraining's l1: 0.145748\tvalid_1's l1: 0.411198\n",
      "[3000]\ttraining's l1: 0.142928\tvalid_1's l1: 0.409311\n",
      "[3500]\ttraining's l1: 0.140525\tvalid_1's l1: 0.406528\n",
      "[4000]\ttraining's l1: 0.137411\tvalid_1's l1: 0.399208\n",
      "[4500]\ttraining's l1: 0.135624\tvalid_1's l1: 0.398445\n",
      "[5000]\ttraining's l1: 0.13427\tvalid_1's l1: 0.398757\n",
      "Early stopping, best iteration is:\n",
      "[4847]\ttraining's l1: 0.134841\tvalid_1's l1: 0.398315\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6773\n",
      "[LightGBM] [Info] Number of data points in the train set: 7706, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.161691\tvalid_1's l1: 0.810856\n",
      "[1000]\ttraining's l1: 0.16008\tvalid_1's l1: 0.803606\n",
      "[1500]\ttraining's l1: 0.156197\tvalid_1's l1: 0.790178\n",
      "[2000]\ttraining's l1: 0.146741\tvalid_1's l1: 0.774646\n",
      "[2500]\ttraining's l1: 0.141713\tvalid_1's l1: 0.768402\n",
      "[3000]\ttraining's l1: 0.138439\tvalid_1's l1: 0.766214\n",
      "[3500]\ttraining's l1: 0.136846\tvalid_1's l1: 0.764124\n",
      "[4000]\ttraining's l1: 0.135036\tvalid_1's l1: 0.762654\n",
      "[4500]\ttraining's l1: 0.133733\tvalid_1's l1: 0.76147\n",
      "[5000]\ttraining's l1: 0.132601\tvalid_1's l1: 0.759669\n",
      "[5500]\ttraining's l1: 0.131589\tvalid_1's l1: 0.757774\n",
      "Early stopping, best iteration is:\n",
      "[5073]\ttraining's l1: 0.13242\tvalid_1's l1: 0.757595\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6758\n",
      "[LightGBM] [Info] Number of data points in the train set: 7497, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.155781\tvalid_1's l1: 0.83973\n",
      "[1000]\ttraining's l1: 0.152334\tvalid_1's l1: 0.83188\n",
      "[1500]\ttraining's l1: 0.146865\tvalid_1's l1: 0.832053\n",
      "[2000]\ttraining's l1: 0.140841\tvalid_1's l1: 0.830946\n",
      "Early stopping, best iteration is:\n",
      "[1750]\ttraining's l1: 0.143948\tvalid_1's l1: 0.830467\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6747\n",
      "[LightGBM] [Info] Number of data points in the train set: 7288, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.153718\tvalid_1's l1: 0.435224\n",
      "[1000]\ttraining's l1: 0.151151\tvalid_1's l1: 0.432497\n",
      "[1500]\ttraining's l1: 0.141338\tvalid_1's l1: 0.432118\n",
      "Early stopping, best iteration is:\n",
      "[1135]\ttraining's l1: 0.14819\tvalid_1's l1: 0.431494\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6740\n",
      "[LightGBM] [Info] Number of data points in the train set: 7079, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.153942\tvalid_1's l1: 0.406171\n",
      "[1000]\ttraining's l1: 0.151329\tvalid_1's l1: 0.402133\n",
      "[1500]\ttraining's l1: 0.141209\tvalid_1's l1: 0.400264\n",
      "[2000]\ttraining's l1: 0.132676\tvalid_1's l1: 0.398148\n",
      "[2500]\ttraining's l1: 0.127151\tvalid_1's l1: 0.398127\n",
      "Early stopping, best iteration is:\n",
      "[2088]\ttraining's l1: 0.131082\tvalid_1's l1: 0.397328\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6731\n",
      "[LightGBM] [Info] Number of data points in the train set: 6870, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.147918\tvalid_1's l1: 0.372551\n",
      "[1000]\ttraining's l1: 0.144943\tvalid_1's l1: 0.369723\n",
      "[1500]\ttraining's l1: 0.142321\tvalid_1's l1: 0.367078\n",
      "[2000]\ttraining's l1: 0.133653\tvalid_1's l1: 0.362115\n",
      "Early stopping, best iteration is:\n",
      "[1931]\ttraining's l1: 0.13467\tvalid_1's l1: 0.361219\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6518\n",
      "[LightGBM] [Info] Number of data points in the train set: 7706, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.182264\tvalid_1's l1: 0.423856\n",
      "[1000]\ttraining's l1: 0.179521\tvalid_1's l1: 0.421752\n",
      "[1500]\ttraining's l1: 0.172045\tvalid_1's l1: 0.418751\n",
      "[2000]\ttraining's l1: 0.162674\tvalid_1's l1: 0.413709\n",
      "[2500]\ttraining's l1: 0.153772\tvalid_1's l1: 0.411098\n",
      "Early stopping, best iteration is:\n",
      "[2314]\ttraining's l1: 0.15616\tvalid_1's l1: 0.410312\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6503\n",
      "[LightGBM] [Info] Number of data points in the train set: 7497, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.175863\tvalid_1's l1: 1.11707\n",
      "[1000]\ttraining's l1: 0.173631\tvalid_1's l1: 1.11199\n",
      "Early stopping, best iteration is:\n",
      "[741]\ttraining's l1: 0.174678\tvalid_1's l1: 1.11092\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6492\n",
      "[LightGBM] [Info] Number of data points in the train set: 7288, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.176655\tvalid_1's l1: 0.491346\n",
      "[1000]\ttraining's l1: 0.174166\tvalid_1's l1: 0.489291\n",
      "Early stopping, best iteration is:\n",
      "[915]\ttraining's l1: 0.174463\tvalid_1's l1: 0.488568\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6485\n",
      "[LightGBM] [Info] Number of data points in the train set: 7079, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.165761\tvalid_1's l1: 0.476188\n",
      "[1000]\ttraining's l1: 0.163655\tvalid_1's l1: 0.474432\n",
      "[1500]\ttraining's l1: 0.15832\tvalid_1's l1: 0.469782\n",
      "[2000]\ttraining's l1: 0.149206\tvalid_1's l1: 0.464238\n",
      "[2500]\ttraining's l1: 0.142982\tvalid_1's l1: 0.461144\n",
      "[3000]\ttraining's l1: 0.139191\tvalid_1's l1: 0.46062\n",
      "Early stopping, best iteration is:\n",
      "[2664]\ttraining's l1: 0.14106\tvalid_1's l1: 0.460209\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6476\n",
      "[LightGBM] [Info] Number of data points in the train set: 6870, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.159209\tvalid_1's l1: 0.453842\n",
      "[1000]\ttraining's l1: 0.145943\tvalid_1's l1: 0.445132\n",
      "[1500]\ttraining's l1: 0.144204\tvalid_1's l1: 0.44452\n",
      "Early stopping, best iteration is:\n",
      "[1111]\ttraining's l1: 0.144739\tvalid_1's l1: 0.4443\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6263\n",
      "[LightGBM] [Info] Number of data points in the train set: 7706, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.19043\tvalid_1's l1: 0.413646\n",
      "[1000]\ttraining's l1: 0.18735\tvalid_1's l1: 0.410729\n",
      "[1500]\ttraining's l1: 0.175721\tvalid_1's l1: 0.402327\n",
      "[2000]\ttraining's l1: 0.165866\tvalid_1's l1: 0.39697\n",
      "[2500]\ttraining's l1: 0.160355\tvalid_1's l1: 0.391509\n",
      "[3000]\ttraining's l1: 0.156876\tvalid_1's l1: 0.391458\n",
      "[3500]\ttraining's l1: 0.155264\tvalid_1's l1: 0.390833\n",
      "[4000]\ttraining's l1: 0.154061\tvalid_1's l1: 0.389872\n",
      "[4500]\ttraining's l1: 0.15275\tvalid_1's l1: 0.389984\n",
      "Early stopping, best iteration is:\n",
      "[4038]\ttraining's l1: 0.153936\tvalid_1's l1: 0.389837\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6248\n",
      "[LightGBM] [Info] Number of data points in the train set: 7497, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.182356\tvalid_1's l1: 1.08312\n",
      "[1000]\ttraining's l1: 0.175324\tvalid_1's l1: 1.07302\n",
      "[1500]\ttraining's l1: 0.163525\tvalid_1's l1: 1.06159\n",
      "[2000]\ttraining's l1: 0.156094\tvalid_1's l1: 1.05645\n",
      "[2500]\ttraining's l1: 0.15319\tvalid_1's l1: 1.05668\n",
      "Early stopping, best iteration is:\n",
      "[2146]\ttraining's l1: 0.154926\tvalid_1's l1: 1.05514\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6237\n",
      "[LightGBM] [Info] Number of data points in the train set: 7288, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.174732\tvalid_1's l1: 0.517467\n",
      "[1000]\ttraining's l1: 0.162846\tvalid_1's l1: 0.516235\n",
      "[1500]\ttraining's l1: 0.149095\tvalid_1's l1: 0.513316\n",
      "[2000]\ttraining's l1: 0.144946\tvalid_1's l1: 0.513128\n",
      "[2500]\ttraining's l1: 0.141439\tvalid_1's l1: 0.512528\n",
      "Early stopping, best iteration is:\n",
      "[2292]\ttraining's l1: 0.142114\tvalid_1's l1: 0.512354\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6230\n",
      "[LightGBM] [Info] Number of data points in the train set: 7079, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.177427\tvalid_1's l1: 0.507661\n",
      "[1000]\ttraining's l1: 0.173527\tvalid_1's l1: 0.501913\n",
      "[1500]\ttraining's l1: 0.163591\tvalid_1's l1: 0.491841\n",
      "[2000]\ttraining's l1: 0.155391\tvalid_1's l1: 0.487252\n",
      "[2500]\ttraining's l1: 0.148868\tvalid_1's l1: 0.478539\n",
      "[3000]\ttraining's l1: 0.144843\tvalid_1's l1: 0.476843\n",
      "[3500]\ttraining's l1: 0.142725\tvalid_1's l1: 0.476838\n",
      "Early stopping, best iteration is:\n",
      "[3347]\ttraining's l1: 0.143094\tvalid_1's l1: 0.476487\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6221\n",
      "[LightGBM] [Info] Number of data points in the train set: 6870, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.172826\tvalid_1's l1: 0.444121\n",
      "[1000]\ttraining's l1: 0.169782\tvalid_1's l1: 0.439238\n",
      "[1500]\ttraining's l1: 0.158467\tvalid_1's l1: 0.431269\n",
      "[2000]\ttraining's l1: 0.148701\tvalid_1's l1: 0.427104\n",
      "[2500]\ttraining's l1: 0.144722\tvalid_1's l1: 0.423527\n",
      "[3000]\ttraining's l1: 0.141454\tvalid_1's l1: 0.42277\n",
      "[3500]\ttraining's l1: 0.139207\tvalid_1's l1: 0.422355\n",
      "[4000]\ttraining's l1: 0.137551\tvalid_1's l1: 0.421643\n",
      "Early stopping, best iteration is:\n",
      "[3897]\ttraining's l1: 0.13786\tvalid_1's l1: 0.421628\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6773\n",
      "[LightGBM] [Info] Number of data points in the train set: 7706, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.162802\tvalid_1's l1: 0.806158\n",
      "[1000]\ttraining's l1: 0.159611\tvalid_1's l1: 0.802625\n",
      "[1500]\ttraining's l1: 0.153054\tvalid_1's l1: 0.792724\n",
      "[2000]\ttraining's l1: 0.144638\tvalid_1's l1: 0.785484\n",
      "[2500]\ttraining's l1: 0.140143\tvalid_1's l1: 0.782294\n",
      "[3000]\ttraining's l1: 0.137341\tvalid_1's l1: 0.778173\n",
      "[3500]\ttraining's l1: 0.135277\tvalid_1's l1: 0.778195\n",
      "Early stopping, best iteration is:\n",
      "[3177]\ttraining's l1: 0.136545\tvalid_1's l1: 0.776519\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6758\n",
      "[LightGBM] [Info] Number of data points in the train set: 7497, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.157349\tvalid_1's l1: 0.873772\n",
      "[1000]\ttraining's l1: 0.152432\tvalid_1's l1: 0.870477\n",
      "Early stopping, best iteration is:\n",
      "[665]\ttraining's l1: 0.15268\tvalid_1's l1: 0.869089\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6747\n",
      "[LightGBM] [Info] Number of data points in the train set: 7288, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.15275\tvalid_1's l1: 0.387416\n",
      "[1000]\ttraining's l1: 0.151112\tvalid_1's l1: 0.386532\n",
      "[1500]\ttraining's l1: 0.146255\tvalid_1's l1: 0.384535\n",
      "[2000]\ttraining's l1: 0.139015\tvalid_1's l1: 0.383199\n",
      "[2500]\ttraining's l1: 0.133388\tvalid_1's l1: 0.382893\n",
      "[3000]\ttraining's l1: 0.130329\tvalid_1's l1: 0.382852\n",
      "Early stopping, best iteration is:\n",
      "[2762]\ttraining's l1: 0.131639\tvalid_1's l1: 0.382418\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6740\n",
      "[LightGBM] [Info] Number of data points in the train set: 7079, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.148857\tvalid_1's l1: 0.415213\n",
      "[1000]\ttraining's l1: 0.143716\tvalid_1's l1: 0.414194\n",
      "[1500]\ttraining's l1: 0.140905\tvalid_1's l1: 0.413572\n",
      "[2000]\ttraining's l1: 0.134161\tvalid_1's l1: 0.410652\n",
      "[2500]\ttraining's l1: 0.129653\tvalid_1's l1: 0.410586\n",
      "[3000]\ttraining's l1: 0.125695\tvalid_1's l1: 0.409308\n",
      "[3500]\ttraining's l1: 0.12363\tvalid_1's l1: 0.409323\n",
      "Early stopping, best iteration is:\n",
      "[3176]\ttraining's l1: 0.124624\tvalid_1's l1: 0.409222\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6731\n",
      "[LightGBM] [Info] Number of data points in the train set: 6870, number of used features: 35\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.144434\tvalid_1's l1: 0.383701\n",
      "[1000]\ttraining's l1: 0.142887\tvalid_1's l1: 0.38253\n",
      "[1500]\ttraining's l1: 0.138654\tvalid_1's l1: 0.375501\n",
      "[2000]\ttraining's l1: 0.130843\tvalid_1's l1: 0.370062\n",
      "[2500]\ttraining's l1: 0.127879\tvalid_1's l1: 0.36962\n",
      "[3000]\ttraining's l1: 0.125683\tvalid_1's l1: 0.369096\n",
      "[3500]\ttraining's l1: 0.124723\tvalid_1's l1: 0.368666\n",
      "[4000]\ttraining's l1: 0.123437\tvalid_1's l1: 0.367704\n",
      "[4500]\ttraining's l1: 0.122689\tvalid_1's l1: 0.367653\n",
      "[5000]\ttraining's l1: 0.121899\tvalid_1's l1: 0.367406\n",
      "[5500]\ttraining's l1: 0.121106\tvalid_1's l1: 0.366632\n",
      "Early stopping, best iteration is:\n",
      "[5116]\ttraining's l1: 0.121611\tvalid_1's l1: 0.366412\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6518\n",
      "[LightGBM] [Info] Number of data points in the train set: 7706, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.18476\tvalid_1's l1: 0.438689\n",
      "[1000]\ttraining's l1: 0.18283\tvalid_1's l1: 0.427122\n",
      "[1500]\ttraining's l1: 0.176525\tvalid_1's l1: 0.423251\n",
      "[2000]\ttraining's l1: 0.165542\tvalid_1's l1: 0.417494\n",
      "[2500]\ttraining's l1: 0.157155\tvalid_1's l1: 0.418216\n",
      "Early stopping, best iteration is:\n",
      "[2339]\ttraining's l1: 0.158576\tvalid_1's l1: 0.41701\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6503\n",
      "[LightGBM] [Info] Number of data points in the train set: 7497, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.179934\tvalid_1's l1: 1.08862\n",
      "[1000]\ttraining's l1: 0.178337\tvalid_1's l1: 1.08177\n",
      "[1500]\ttraining's l1: 0.170792\tvalid_1's l1: 1.08381\n",
      "Early stopping, best iteration is:\n",
      "[1353]\ttraining's l1: 0.173729\tvalid_1's l1: 1.08132\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6492\n",
      "[LightGBM] [Info] Number of data points in the train set: 7288, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.166596\tvalid_1's l1: 0.477553\n",
      "[1000]\ttraining's l1: 0.163953\tvalid_1's l1: 0.475322\n",
      "[1500]\ttraining's l1: 0.15454\tvalid_1's l1: 0.473\n",
      "[2000]\ttraining's l1: 0.14737\tvalid_1's l1: 0.472951\n",
      "Early stopping, best iteration is:\n",
      "[1691]\ttraining's l1: 0.151838\tvalid_1's l1: 0.471906\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6485\n",
      "[LightGBM] [Info] Number of data points in the train set: 7079, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.163176\tvalid_1's l1: 0.442961\n",
      "[1000]\ttraining's l1: 0.159897\tvalid_1's l1: 0.439953\n",
      "[1500]\ttraining's l1: 0.15269\tvalid_1's l1: 0.435204\n",
      "[2000]\ttraining's l1: 0.145423\tvalid_1's l1: 0.433495\n",
      "[2500]\ttraining's l1: 0.141557\tvalid_1's l1: 0.432441\n",
      "[3000]\ttraining's l1: 0.139243\tvalid_1's l1: 0.431967\n",
      "[3500]\ttraining's l1: 0.137204\tvalid_1's l1: 0.431155\n",
      "Early stopping, best iteration is:\n",
      "[3419]\ttraining's l1: 0.13744\tvalid_1's l1: 0.431113\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6476\n",
      "[LightGBM] [Info] Number of data points in the train set: 6870, number of used features: 34\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.161941\tvalid_1's l1: 0.460117\n",
      "[1000]\ttraining's l1: 0.155063\tvalid_1's l1: 0.452885\n",
      "[1500]\ttraining's l1: 0.149729\tvalid_1's l1: 0.447165\n",
      "[2000]\ttraining's l1: 0.142813\tvalid_1's l1: 0.439646\n",
      "[2500]\ttraining's l1: 0.138588\tvalid_1's l1: 0.437312\n",
      "[3000]\ttraining's l1: 0.136188\tvalid_1's l1: 0.434941\n",
      "Early stopping, best iteration is:\n",
      "[2993]\ttraining's l1: 0.136208\tvalid_1's l1: 0.434937\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6263\n",
      "[LightGBM] [Info] Number of data points in the train set: 7706, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.192936\tvalid_1's l1: 0.415949\n",
      "[1000]\ttraining's l1: 0.188648\tvalid_1's l1: 0.409889\n",
      "[1500]\ttraining's l1: 0.17549\tvalid_1's l1: 0.40123\n",
      "[2000]\ttraining's l1: 0.165182\tvalid_1's l1: 0.392607\n",
      "[2500]\ttraining's l1: 0.159968\tvalid_1's l1: 0.389511\n",
      "[3000]\ttraining's l1: 0.157124\tvalid_1's l1: 0.388888\n",
      "[3500]\ttraining's l1: 0.154708\tvalid_1's l1: 0.387485\n",
      "[4000]\ttraining's l1: 0.153121\tvalid_1's l1: 0.38708\n",
      "[4500]\ttraining's l1: 0.15171\tvalid_1's l1: 0.38654\n",
      "[5000]\ttraining's l1: 0.150414\tvalid_1's l1: 0.386481\n",
      "[5500]\ttraining's l1: 0.149672\tvalid_1's l1: 0.385792\n",
      "[6000]\ttraining's l1: 0.148216\tvalid_1's l1: 0.381573\n",
      "[6500]\ttraining's l1: 0.14718\tvalid_1's l1: 0.380278\n",
      "[7000]\ttraining's l1: 0.145752\tvalid_1's l1: 0.378283\n",
      "[7500]\ttraining's l1: 0.145264\tvalid_1's l1: 0.378675\n",
      "Early stopping, best iteration is:\n",
      "[7003]\ttraining's l1: 0.145748\tvalid_1's l1: 0.378274\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6248\n",
      "[LightGBM] [Info] Number of data points in the train set: 7497, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.180427\tvalid_1's l1: 1.09204\n",
      "[1000]\ttraining's l1: 0.17705\tvalid_1's l1: 1.08601\n",
      "[1500]\ttraining's l1: 0.169349\tvalid_1's l1: 1.0842\n",
      "[2000]\ttraining's l1: 0.160594\tvalid_1's l1: 1.08201\n",
      "[2500]\ttraining's l1: 0.152038\tvalid_1's l1: 1.08118\n",
      "Early stopping, best iteration is:\n",
      "[2323]\ttraining's l1: 0.154616\tvalid_1's l1: 1.08064\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6237\n",
      "[LightGBM] [Info] Number of data points in the train set: 7288, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.18286\tvalid_1's l1: 0.55278\n",
      "[1000]\ttraining's l1: 0.17974\tvalid_1's l1: 0.550271\n",
      "[1500]\ttraining's l1: 0.169052\tvalid_1's l1: 0.54271\n",
      "[2000]\ttraining's l1: 0.160553\tvalid_1's l1: 0.539085\n",
      "[2500]\ttraining's l1: 0.154758\tvalid_1's l1: 0.538369\n",
      "[3000]\ttraining's l1: 0.151242\tvalid_1's l1: 0.537039\n",
      "Early stopping, best iteration is:\n",
      "[2880]\ttraining's l1: 0.152271\tvalid_1's l1: 0.536723\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6230\n",
      "[LightGBM] [Info] Number of data points in the train set: 7079, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.186541\tvalid_1's l1: 0.494291\n",
      "[1000]\ttraining's l1: 0.178997\tvalid_1's l1: 0.486645\n",
      "[1500]\ttraining's l1: 0.166434\tvalid_1's l1: 0.477024\n",
      "[2000]\ttraining's l1: 0.155558\tvalid_1's l1: 0.468709\n",
      "[2500]\ttraining's l1: 0.150965\tvalid_1's l1: 0.465947\n",
      "[3000]\ttraining's l1: 0.145921\tvalid_1's l1: 0.466012\n",
      "Early stopping, best iteration is:\n",
      "[2891]\ttraining's l1: 0.148654\tvalid_1's l1: 0.464379\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6221\n",
      "[LightGBM] [Info] Number of data points in the train set: 6870, number of used features: 33\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.179833\tvalid_1's l1: 0.431016\n",
      "[1000]\ttraining's l1: 0.173765\tvalid_1's l1: 0.426619\n",
      "[1500]\ttraining's l1: 0.159547\tvalid_1's l1: 0.41726\n",
      "[2000]\ttraining's l1: 0.149748\tvalid_1's l1: 0.410331\n",
      "[2500]\ttraining's l1: 0.145499\tvalid_1's l1: 0.408541\n",
      "[3000]\ttraining's l1: 0.1427\tvalid_1's l1: 0.406928\n",
      "[3500]\ttraining's l1: 0.139215\tvalid_1's l1: 0.402748\n",
      "[4000]\ttraining's l1: 0.137653\tvalid_1's l1: 0.402627\n",
      "[4500]\ttraining's l1: 0.136769\tvalid_1's l1: 0.402595\n",
      "[5000]\ttraining's l1: 0.135182\tvalid_1's l1: 0.401576\n",
      "[5500]\ttraining's l1: 0.134512\tvalid_1's l1: 0.401504\n",
      "[6000]\ttraining's l1: 0.133685\tvalid_1's l1: 0.401299\n",
      "[6500]\ttraining's l1: 0.133105\tvalid_1's l1: 0.401401\n",
      "Early stopping, best iteration is:\n",
      "[6028]\ttraining's l1: 0.133633\tvalid_1's l1: 0.401247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, GroupKFold, TimeSeriesSplit, StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "\n",
    "# test_month = 37\n",
    "lgb_models = []\n",
    "df_test['label1'] = 0\n",
    "oof_predictions = df_train.copy()\n",
    "oof_predictions['oof1'] = 0\n",
    "oof_predictions['label_sum'] = np.log1p(oof_predictions['label_sum'])\n",
    "\n",
    "seedlist = [3333+i**2 for i in range(5)]\n",
    "monthlist = [40, 41, 42]\n",
    "\n",
    "for seed in seedlist:\n",
    "    \n",
    "    lgb_params = {\n",
    "        \"objective\": \"mae\", \n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"metric\": \"mae\",\n",
    "        'num_leaves': 2**5-1,\n",
    "        'max_depth':-1,\n",
    "        'learning_rate': 0.02,   \n",
    "        'colsample_bytree': 0.95,\n",
    "        'subsample': 0.95,\n",
    "        'subsample_freq': 1,\n",
    "        'device': 'cpu',\n",
    "        'seed': seed,\n",
    "        'n_estimators':5000,\n",
    "    }\n",
    "\n",
    "    \n",
    "    df_test['pred1'] = 0\n",
    "    for shift, test_month in enumerate(monthlist):\n",
    "        df = pd.concat([df_train.copy(), df_test.copy()])\n",
    "        df = getFE(df, shift=shift)\n",
    "        df = getFirstMonth(df)\n",
    "        \n",
    "        df_train_ = df[df['label_sum'].notna()].reset_index(drop=True)\n",
    "        df_test_ = df[df['label_sum'].isna()].reset_index(drop=True)\n",
    "        \n",
    "#         df_train_,df_test_ = target_encode(df_train_, df_test_)\n",
    "        \n",
    "        not_use = ['product_id']\n",
    "        # cate_features = ['product_id','type']\n",
    "        features = [c for c in df_test_.columns if c not in ['start_sale', 'pred1','label1', 'pred2', 'label2', 'date','year','label_sum', 'season', 'month','time']+not_use]\n",
    "        label = ['label_sum']\n",
    "        df_train_[label] = np.log1p(df_train_[label])\n",
    "        \n",
    "        X_tr_val = df_train_.copy()\n",
    "        X_te     = df_test_.loc[df_test_.time == test_month, features]\n",
    "        \n",
    "        kfold = 5\n",
    "        for fold in range(kfold):\n",
    "\n",
    "            X_train,X_valid = X_tr_val.loc[X_tr_val.time < (39-fold), features], X_tr_val.loc[X_tr_val.time == (39-fold), features]\n",
    "            y_train,y_valid = X_tr_val.loc[X_tr_val.time < (39-fold), label], X_tr_val.loc[X_tr_val.time == (39-fold), label]\n",
    "        \n",
    "            lgbm_train = lgb.Dataset(X_train,y_train)  \n",
    "            lgbm_valid = lgb.Dataset(X_valid,y_valid)\n",
    "\n",
    "            model_mae = lgb.train(params=lgb_params, \n",
    "                          train_set=lgbm_train,\n",
    "                          valid_sets=[lgbm_train, lgbm_valid], \n",
    "    #                       feval = lgb_ifly_metric,\n",
    "                          callbacks=[lgb.early_stopping(200)],\n",
    "                          verbose_eval=500,)\n",
    "        \n",
    "            df_test.loc[df_test.time == test_month, 'pred1'] += model_mae.predict(X_te) / kfold\n",
    "            \n",
    "            oof_predictions.loc[oof_predictions.time == (39-fold), 'oof1'] += model_mae.predict(X_valid) / len(seedlist) / len(monthlist)\n",
    "\n",
    "    df_test['label1'] += df_test['pred1'] / len(seedlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "636196d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is_sale_day_sum</td>\n",
       "      <td>1668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is_sale_day_count</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>type</td>\n",
       "      <td>2548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>order</td>\n",
       "      <td>4643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>start_stock</td>\n",
       "      <td>4325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>end_stock</td>\n",
       "      <td>6201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stock_diff</td>\n",
       "      <td>5736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stock_sum</td>\n",
       "      <td>5055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>type_stock_diff_sum</td>\n",
       "      <td>8397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>product_year_stock_diff_sum</td>\n",
       "      <td>8793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>type_stock_diff_ratio</td>\n",
       "      <td>7975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>product_year_stock_diff_ratio</td>\n",
       "      <td>8952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>order_sale_ratio</td>\n",
       "      <td>6618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stock_diff_1</td>\n",
       "      <td>7040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stock_sum_1</td>\n",
       "      <td>4836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>order_1</td>\n",
       "      <td>4078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>start_stock_1</td>\n",
       "      <td>4646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>end_stock_1</td>\n",
       "      <td>3979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>stock_diff_2</td>\n",
       "      <td>7162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>stock_sum_2</td>\n",
       "      <td>4514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>order_2</td>\n",
       "      <td>4111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>start_stock_2</td>\n",
       "      <td>4066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>end_stock_2</td>\n",
       "      <td>4388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>stock_diff_3</td>\n",
       "      <td>6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>stock_sum_3</td>\n",
       "      <td>4690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>order_3</td>\n",
       "      <td>4854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>start_stock_3</td>\n",
       "      <td>5211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>end_stock_3</td>\n",
       "      <td>4157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>label_sum_3</td>\n",
       "      <td>6882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>label_sum_4</td>\n",
       "      <td>6030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>label_sum_5</td>\n",
       "      <td>6938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>product_id_stock_diff_mean</td>\n",
       "      <td>13292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>type_stock_diff_mean</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature   gain\n",
       "0                 is_sale_day_sum   1668\n",
       "1               is_sale_day_count   1509\n",
       "2                            type   2548\n",
       "3                           order   4643\n",
       "4                     start_stock   4325\n",
       "5                       end_stock   6201\n",
       "6                      stock_diff   5736\n",
       "7                       stock_sum   5055\n",
       "8             type_stock_diff_sum   8397\n",
       "9     product_year_stock_diff_sum   8793\n",
       "10          type_stock_diff_ratio   7975\n",
       "11  product_year_stock_diff_ratio   8952\n",
       "12               order_sale_ratio   6618\n",
       "13                   stock_diff_1   7040\n",
       "14                    stock_sum_1   4836\n",
       "15                        order_1   4078\n",
       "16                  start_stock_1   4646\n",
       "17                    end_stock_1   3979\n",
       "18                   stock_diff_2   7162\n",
       "19                    stock_sum_2   4514\n",
       "20                        order_2   4111\n",
       "21                  start_stock_2   4066\n",
       "22                    end_stock_2   4388\n",
       "23                   stock_diff_3   6758\n",
       "24                    stock_sum_3   4690\n",
       "25                        order_3   4854\n",
       "26                  start_stock_3   5211\n",
       "27                    end_stock_3   4157\n",
       "28                    label_sum_3   6882\n",
       "29                    label_sum_4   6030\n",
       "30                    label_sum_5   6938\n",
       "31     product_id_stock_diff_mean  13292\n",
       "32           type_stock_diff_mean    788"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['feature'] = model_mae.feature_name()\n",
    "feature_importances['gain'] = model_mae.feature_importance()\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "567b5fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7499052496180584"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_month = 35\n",
    "scores = evalScore(oof_predictions[oof_predictions.time>=test_month].reset_index(drop=True), oof_predictions.loc[oof_predictions.time>=test_month,'oof1'].reset_index(drop=True))\n",
    "scores\n",
    "\n",
    "# 0.7161011656941316 drop stock_sum 0.7175194303234131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f15b31e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.09242\ttrain-mae:2.89669\tvalid-rmse:6.58908\tvalid-mae:6.54792\n",
      "[500]\ttrain-rmse:0.52256\ttrain-mae:0.13897\tvalid-rmse:1.07151\tvalid-mae:0.64589\n",
      "[1000]\ttrain-rmse:0.44496\ttrain-mae:0.11049\tvalid-rmse:0.97783\tvalid-mae:0.57127\n",
      "[1500]\ttrain-rmse:0.39050\ttrain-mae:0.09143\tvalid-rmse:0.92078\tvalid-mae:0.54010\n",
      "[2000]\ttrain-rmse:0.34234\ttrain-mae:0.07615\tvalid-rmse:0.88950\tvalid-mae:0.52651\n",
      "[2500]\ttrain-rmse:0.30580\ttrain-mae:0.06426\tvalid-rmse:0.87455\tvalid-mae:0.51688\n",
      "[3000]\ttrain-rmse:0.27532\ttrain-mae:0.05460\tvalid-rmse:0.87350\tvalid-mae:0.51512\n",
      "[3334]\ttrain-rmse:0.25865\ttrain-mae:0.04910\tvalid-rmse:0.87341\tvalid-mae:0.51760\n",
      "[0]\ttrain-rmse:4.05928\ttrain-mae:2.84325\tvalid-rmse:5.25039\tvalid-mae:4.91110\n",
      "[500]\ttrain-rmse:0.51671\ttrain-mae:0.13189\tvalid-rmse:1.51543\tvalid-mae:0.99550\n",
      "[510]\ttrain-rmse:0.51426\ttrain-mae:0.13108\tvalid-rmse:1.51496\tvalid-mae:0.99683\n",
      "[0]\ttrain-rmse:3.98951\ttrain-mae:2.76336\tvalid-rmse:5.97565\tvalid-mae:5.61754\n",
      "[500]\ttrain-rmse:0.51570\ttrain-mae:0.12721\tvalid-rmse:1.26384\tvalid-mae:0.53023\n",
      "[857]\ttrain-rmse:0.46461\ttrain-mae:0.10899\tvalid-rmse:1.26012\tvalid-mae:0.53714\n",
      "[0]\ttrain-rmse:3.91659\ttrain-mae:2.67939\tvalid-rmse:6.10481\tvalid-mae:5.73148\n",
      "[500]\ttrain-rmse:0.50750\ttrain-mae:0.12583\tvalid-rmse:1.24442\tvalid-mae:0.42385\n",
      "[856]\ttrain-rmse:0.44705\ttrain-mae:0.10435\tvalid-rmse:1.24250\tvalid-mae:0.42289\n",
      "[0]\ttrain-rmse:3.84289\ttrain-mae:2.60021\tvalid-rmse:5.89765\tvalid-mae:5.32948\n",
      "[500]\ttrain-rmse:0.49998\ttrain-mae:0.12127\tvalid-rmse:0.93346\tvalid-mae:0.36461\n",
      "[943]\ttrain-rmse:0.42744\ttrain-mae:0.09628\tvalid-rmse:0.91463\tvalid-mae:0.36337\n",
      "[0]\ttrain-rmse:4.10858\ttrain-mae:2.90270\tvalid-rmse:6.29768\tvalid-mae:6.24743\n",
      "[500]\ttrain-rmse:0.56978\ttrain-mae:0.16041\tvalid-rmse:0.96389\tvalid-mae:0.41532\n",
      "[1000]\ttrain-rmse:0.49491\ttrain-mae:0.12831\tvalid-rmse:0.88817\tvalid-mae:0.40689\n",
      "[1251]\ttrain-rmse:0.46636\ttrain-mae:0.11740\tvalid-rmse:0.87844\tvalid-mae:0.40689\n",
      "[0]\ttrain-rmse:4.07938\ttrain-mae:2.85271\tvalid-rmse:5.36578\tvalid-mae:5.01369\n",
      "[487]\ttrain-rmse:0.56564\ttrain-mae:0.15279\tvalid-rmse:1.56481\tvalid-mae:1.09087\n",
      "[0]\ttrain-rmse:4.00521\ttrain-mae:2.76959\tvalid-rmse:6.01922\tvalid-mae:5.65106\n",
      "[500]\ttrain-rmse:0.54477\ttrain-mae:0.14279\tvalid-rmse:1.26317\tvalid-mae:0.52145\n",
      "[515]\ttrain-rmse:0.54196\ttrain-mae:0.14153\tvalid-rmse:1.26231\tvalid-mae:0.52116\n",
      "[0]\ttrain-rmse:3.93153\ttrain-mae:2.68565\tvalid-rmse:6.14406\tvalid-mae:5.76509\n",
      "[500]\ttrain-rmse:0.53698\ttrain-mae:0.13839\tvalid-rmse:1.12618\tvalid-mae:0.44709\n",
      "[1000]\ttrain-rmse:0.46950\ttrain-mae:0.11161\tvalid-rmse:1.11380\tvalid-mae:0.43949\n",
      "[1242]\ttrain-rmse:0.44196\ttrain-mae:0.10167\tvalid-rmse:1.10695\tvalid-mae:0.44146\n",
      "[0]\ttrain-rmse:3.85807\ttrain-mae:2.60685\tvalid-rmse:5.97180\tvalid-mae:5.39022\n",
      "[500]\ttrain-rmse:0.52928\ttrain-mae:0.13508\tvalid-rmse:1.13878\tvalid-mae:0.47251\n",
      "[955]\ttrain-rmse:0.45414\ttrain-mae:0.10640\tvalid-rmse:1.15524\tvalid-mae:0.47486\n",
      "[0]\ttrain-rmse:4.11656\ttrain-mae:2.90801\tvalid-rmse:6.30311\tvalid-mae:6.25189\n",
      "[500]\ttrain-rmse:0.58865\ttrain-mae:0.16837\tvalid-rmse:0.91514\tvalid-mae:0.38890\n",
      "[1000]\ttrain-rmse:0.50804\ttrain-mae:0.13279\tvalid-rmse:0.87957\tvalid-mae:0.38341\n",
      "[1022]\ttrain-rmse:0.50590\ttrain-mae:0.13195\tvalid-rmse:0.87919\tvalid-mae:0.38374\n",
      "[0]\ttrain-rmse:4.08767\ttrain-mae:2.85806\tvalid-rmse:5.33118\tvalid-mae:4.97127\n",
      "[500]\ttrain-rmse:0.56680\ttrain-mae:0.15679\tvalid-rmse:1.63713\tvalid-mae:1.01161\n",
      "[896]\ttrain-rmse:0.50183\ttrain-mae:0.12776\tvalid-rmse:1.63416\tvalid-mae:1.02492\n",
      "[0]\ttrain-rmse:4.00845\ttrain-mae:2.77222\tvalid-rmse:6.03805\tvalid-mae:5.67217\n",
      "[500]\ttrain-rmse:0.55476\ttrain-mae:0.14982\tvalid-rmse:1.27306\tvalid-mae:0.52362\n",
      "[624]\ttrain-rmse:0.53347\ttrain-mae:0.13963\tvalid-rmse:1.27394\tvalid-mae:0.52740\n",
      "[0]\ttrain-rmse:3.93454\ttrain-mae:2.68775\tvalid-rmse:6.16951\tvalid-mae:5.78833\n",
      "[500]\ttrain-rmse:0.54338\ttrain-mae:0.14341\tvalid-rmse:1.11684\tvalid-mae:0.48137\n",
      "[1000]\ttrain-rmse:0.46869\ttrain-mae:0.11110\tvalid-rmse:1.09629\tvalid-mae:0.46597\n",
      "[1500]\ttrain-rmse:0.41935\ttrain-mae:0.09301\tvalid-rmse:1.08483\tvalid-mae:0.46055\n",
      "[1996]\ttrain-rmse:0.37078\ttrain-mae:0.07856\tvalid-rmse:1.07476\tvalid-mae:0.46317\n",
      "[0]\ttrain-rmse:3.86313\ttrain-mae:2.61001\tvalid-rmse:5.95597\tvalid-mae:5.37494\n",
      "[500]\ttrain-rmse:0.53795\ttrain-mae:0.14105\tvalid-rmse:1.01124\tvalid-mae:0.42442\n",
      "[931]\ttrain-rmse:0.47185\ttrain-mae:0.11280\tvalid-rmse:1.01855\tvalid-mae:0.42081\n",
      "[0]\ttrain-rmse:4.09300\ttrain-mae:2.89699\tvalid-rmse:6.58870\tvalid-mae:6.54758\n",
      "[500]\ttrain-rmse:0.52411\ttrain-mae:0.13761\tvalid-rmse:0.99343\tvalid-mae:0.58940\n",
      "[1000]\ttrain-rmse:0.44692\ttrain-mae:0.10929\tvalid-rmse:0.90998\tvalid-mae:0.54499\n",
      "[1500]\ttrain-rmse:0.39262\ttrain-mae:0.09091\tvalid-rmse:0.87238\tvalid-mae:0.53265\n",
      "[1655]\ttrain-rmse:0.37565\ttrain-mae:0.08560\tvalid-rmse:0.86953\tvalid-mae:0.52806\n",
      "[0]\ttrain-rmse:4.05971\ttrain-mae:2.84334\tvalid-rmse:5.31720\tvalid-mae:4.97363\n",
      "[500]\ttrain-rmse:0.51817\ttrain-mae:0.13214\tvalid-rmse:1.55475\tvalid-mae:1.07630\n",
      "[516]\ttrain-rmse:0.51418\ttrain-mae:0.13094\tvalid-rmse:1.55462\tvalid-mae:1.07727\n",
      "[0]\ttrain-rmse:3.98759\ttrain-mae:2.76184\tvalid-rmse:5.97036\tvalid-mae:5.61341\n",
      "[500]\ttrain-rmse:0.52470\ttrain-mae:0.13067\tvalid-rmse:1.30205\tvalid-mae:0.51110\n",
      "[527]\ttrain-rmse:0.51992\ttrain-mae:0.12881\tvalid-rmse:1.30084\tvalid-mae:0.51114\n",
      "[0]\ttrain-rmse:3.91450\ttrain-mae:2.67777\tvalid-rmse:6.09934\tvalid-mae:5.72484\n",
      "[500]\ttrain-rmse:0.49664\ttrain-mae:0.12252\tvalid-rmse:1.19539\tvalid-mae:0.41474\n",
      "[775]\ttrain-rmse:0.45796\ttrain-mae:0.10776\tvalid-rmse:1.19171\tvalid-mae:0.41469\n",
      "[0]\ttrain-rmse:3.84158\ttrain-mae:2.59927\tvalid-rmse:5.89650\tvalid-mae:5.32792\n",
      "[500]\ttrain-rmse:0.49442\ttrain-mae:0.12041\tvalid-rmse:0.94939\tvalid-mae:0.37750\n",
      "[557]\ttrain-rmse:0.48345\ttrain-mae:0.11641\tvalid-rmse:0.95094\tvalid-mae:0.37836\n",
      "[0]\ttrain-rmse:4.11227\ttrain-mae:2.90524\tvalid-rmse:6.30064\tvalid-mae:6.24933\n",
      "[500]\ttrain-rmse:0.56930\ttrain-mae:0.15740\tvalid-rmse:1.01929\tvalid-mae:0.42936\n",
      "[805]\ttrain-rmse:0.51842\ttrain-mae:0.13593\tvalid-rmse:0.97470\tvalid-mae:0.42998\n",
      "[0]\ttrain-rmse:4.08139\ttrain-mae:2.85237\tvalid-rmse:5.36331\tvalid-mae:5.00639\n",
      "[500]\ttrain-rmse:0.56735\ttrain-mae:0.15064\tvalid-rmse:1.59347\tvalid-mae:1.04191\n",
      "[522]\ttrain-rmse:0.56317\ttrain-mae:0.14869\tvalid-rmse:1.59523\tvalid-mae:1.04260\n",
      "[0]\ttrain-rmse:4.00854\ttrain-mae:2.77169\tvalid-rmse:6.01975\tvalid-mae:5.65185\n",
      "[500]\ttrain-rmse:0.55734\ttrain-mae:0.14558\tvalid-rmse:1.26826\tvalid-mae:0.51870\n",
      "[663]\ttrain-rmse:0.52687\ttrain-mae:0.13315\tvalid-rmse:1.26812\tvalid-mae:0.52292\n",
      "[0]\ttrain-rmse:3.93547\ttrain-mae:2.68819\tvalid-rmse:6.14623\tvalid-mae:5.76647\n",
      "[500]\ttrain-rmse:0.54500\ttrain-mae:0.13952\tvalid-rmse:1.13816\tvalid-mae:0.45071\n",
      "[721]\ttrain-rmse:0.50948\ttrain-mae:0.12503\tvalid-rmse:1.13626\tvalid-mae:0.45113\n",
      "[0]\ttrain-rmse:3.85605\ttrain-mae:2.60540\tvalid-rmse:5.97072\tvalid-mae:5.38915\n",
      "[500]\ttrain-rmse:0.54226\ttrain-mae:0.13845\tvalid-rmse:1.18742\tvalid-mae:0.49662\n",
      "[639]\ttrain-rmse:0.51752\ttrain-mae:0.12856\tvalid-rmse:1.19114\tvalid-mae:0.49860\n",
      "[0]\ttrain-rmse:4.11966\ttrain-mae:2.91047\tvalid-rmse:6.30117\tvalid-mae:6.24986\n",
      "[500]\ttrain-rmse:0.58638\ttrain-mae:0.16800\tvalid-rmse:0.91668\tvalid-mae:0.39795\n",
      "[1000]\ttrain-rmse:0.50840\ttrain-mae:0.13365\tvalid-rmse:0.87846\tvalid-mae:0.39290\n",
      "[1141]\ttrain-rmse:0.48713\ttrain-mae:0.12601\tvalid-rmse:0.86947\tvalid-mae:0.39550\n",
      "[0]\ttrain-rmse:4.08674\ttrain-mae:2.85738\tvalid-rmse:5.32870\tvalid-mae:4.96694\n",
      "[500]\ttrain-rmse:0.57709\ttrain-mae:0.15922\tvalid-rmse:1.59520\tvalid-mae:1.04302\n",
      "[757]\ttrain-rmse:0.53123\ttrain-mae:0.13881\tvalid-rmse:1.59769\tvalid-mae:1.06368\n",
      "[0]\ttrain-rmse:4.01323\ttrain-mae:2.77515\tvalid-rmse:6.04299\tvalid-mae:5.67685\n",
      "[500]\ttrain-rmse:0.55932\ttrain-mae:0.15091\tvalid-rmse:1.28622\tvalid-mae:0.53858\n",
      "[617]\ttrain-rmse:0.53846\ttrain-mae:0.14107\tvalid-rmse:1.28859\tvalid-mae:0.54025\n",
      "[0]\ttrain-rmse:3.93838\ttrain-mae:2.69034\tvalid-rmse:6.17151\tvalid-mae:5.78947\n",
      "[500]\ttrain-rmse:0.54560\ttrain-mae:0.14426\tvalid-rmse:1.13339\tvalid-mae:0.48000\n",
      "[1000]\ttrain-rmse:0.47782\ttrain-mae:0.11426\tvalid-rmse:1.12158\tvalid-mae:0.47099\n",
      "[1500]\ttrain-rmse:0.42952\ttrain-mae:0.09616\tvalid-rmse:1.10661\tvalid-mae:0.46409\n",
      "[1760]\ttrain-rmse:0.40556\ttrain-mae:0.08827\tvalid-rmse:1.10131\tvalid-mae:0.46527\n",
      "[0]\ttrain-rmse:3.86227\ttrain-mae:2.60903\tvalid-rmse:5.96196\tvalid-mae:5.38032\n",
      "[500]\ttrain-rmse:0.53789\ttrain-mae:0.14140\tvalid-rmse:0.97943\tvalid-mae:0.41798\n",
      "[766]\ttrain-rmse:0.49039\ttrain-mae:0.12091\tvalid-rmse:0.98501\tvalid-mae:0.41942\n",
      "[0]\ttrain-rmse:4.09313\ttrain-mae:2.89699\tvalid-rmse:6.59204\tvalid-mae:6.55096\n",
      "[500]\ttrain-rmse:0.52703\ttrain-mae:0.13863\tvalid-rmse:0.96216\tvalid-mae:0.53262\n",
      "[1000]\ttrain-rmse:0.45216\ttrain-mae:0.11031\tvalid-rmse:0.88810\tvalid-mae:0.50304\n",
      "[1500]\ttrain-rmse:0.39729\ttrain-mae:0.09152\tvalid-rmse:0.82355\tvalid-mae:0.48070\n",
      "[2000]\ttrain-rmse:0.35331\ttrain-mae:0.07717\tvalid-rmse:0.79825\tvalid-mae:0.47283\n",
      "[2500]\ttrain-rmse:0.31576\ttrain-mae:0.06594\tvalid-rmse:0.78789\tvalid-mae:0.46986\n",
      "[2722]\ttrain-rmse:0.30105\ttrain-mae:0.06127\tvalid-rmse:0.78437\tvalid-mae:0.46853\n",
      "[0]\ttrain-rmse:4.06112\ttrain-mae:2.84490\tvalid-rmse:5.34223\tvalid-mae:4.97336\n",
      "[500]\ttrain-rmse:0.51729\ttrain-mae:0.13238\tvalid-rmse:1.52315\tvalid-mae:0.93867\n",
      "[637]\ttrain-rmse:0.49468\ttrain-mae:0.12377\tvalid-rmse:1.52551\tvalid-mae:0.94426\n",
      "[0]\ttrain-rmse:3.99130\ttrain-mae:2.76483\tvalid-rmse:5.97601\tvalid-mae:5.61850\n",
      "[500]\ttrain-rmse:0.52165\ttrain-mae:0.13014\tvalid-rmse:1.30041\tvalid-mae:0.51782\n",
      "[811]\ttrain-rmse:0.47777\ttrain-mae:0.11333\tvalid-rmse:1.29199\tvalid-mae:0.52138\n",
      "[0]\ttrain-rmse:3.91487\ttrain-mae:2.67938\tvalid-rmse:6.10526\tvalid-mae:5.73164\n",
      "[500]\ttrain-rmse:0.50534\ttrain-mae:0.12295\tvalid-rmse:1.20511\tvalid-mae:0.41446\n",
      "[902]\ttrain-rmse:0.44508\ttrain-mae:0.10145\tvalid-rmse:1.20148\tvalid-mae:0.41450\n",
      "[0]\ttrain-rmse:3.84393\ttrain-mae:2.60150\tvalid-rmse:5.98422\tvalid-mae:5.40912\n",
      "[500]\ttrain-rmse:0.49947\ttrain-mae:0.12099\tvalid-rmse:0.99248\tvalid-mae:0.41168\n",
      "[619]\ttrain-rmse:0.47626\ttrain-mae:0.11300\tvalid-rmse:0.99359\tvalid-mae:0.41225\n",
      "[0]\ttrain-rmse:4.11146\ttrain-mae:2.90440\tvalid-rmse:6.30605\tvalid-mae:6.25663\n",
      "[500]\ttrain-rmse:0.56812\ttrain-mae:0.15865\tvalid-rmse:0.97919\tvalid-mae:0.41097\n",
      "[1000]\ttrain-rmse:0.49154\ttrain-mae:0.12709\tvalid-rmse:0.85937\tvalid-mae:0.39288\n",
      "[1245]\ttrain-rmse:0.46129\ttrain-mae:0.11591\tvalid-rmse:0.85039\tvalid-mae:0.40335\n",
      "[0]\ttrain-rmse:4.07954\ttrain-mae:2.85302\tvalid-rmse:5.35574\tvalid-mae:4.99863\n",
      "[500]\ttrain-rmse:0.55794\ttrain-mae:0.14968\tvalid-rmse:1.61853\tvalid-mae:1.03950\n",
      "[503]\ttrain-rmse:0.55734\ttrain-mae:0.14940\tvalid-rmse:1.61898\tvalid-mae:1.03979\n",
      "[0]\ttrain-rmse:4.00693\ttrain-mae:2.77060\tvalid-rmse:6.02083\tvalid-mae:5.65332\n",
      "[458]\ttrain-rmse:0.55768\ttrain-mae:0.14709\tvalid-rmse:1.27414\tvalid-mae:0.52389\n",
      "[0]\ttrain-rmse:3.92878\ttrain-mae:2.68457\tvalid-rmse:6.14316\tvalid-mae:5.76539\n",
      "[500]\ttrain-rmse:0.53392\ttrain-mae:0.13611\tvalid-rmse:1.13903\tvalid-mae:0.48346\n",
      "[1000]\ttrain-rmse:0.46116\ttrain-mae:0.10718\tvalid-rmse:1.11971\tvalid-mae:0.46581\n",
      "[1500]\ttrain-rmse:0.41287\ttrain-mae:0.09097\tvalid-rmse:1.09856\tvalid-mae:0.45768\n",
      "[1838]\ttrain-rmse:0.38106\ttrain-mae:0.08118\tvalid-rmse:1.09390\tvalid-mae:0.45850\n",
      "[0]\ttrain-rmse:3.85796\ttrain-mae:2.60676\tvalid-rmse:5.97169\tvalid-mae:5.39000\n",
      "[500]\ttrain-rmse:0.53112\ttrain-mae:0.13515\tvalid-rmse:1.16432\tvalid-mae:0.49629\n",
      "[977]\ttrain-rmse:0.46234\ttrain-mae:0.10926\tvalid-rmse:1.16877\tvalid-mae:0.49264\n",
      "[0]\ttrain-rmse:4.11901\ttrain-mae:2.90991\tvalid-rmse:6.30343\tvalid-mae:6.25214\n",
      "[500]\ttrain-rmse:0.58095\ttrain-mae:0.16703\tvalid-rmse:0.82889\tvalid-mae:0.37255\n",
      "[965]\ttrain-rmse:0.50019\ttrain-mae:0.13179\tvalid-rmse:0.77645\tvalid-mae:0.36704\n",
      "[0]\ttrain-rmse:4.08379\ttrain-mae:2.85620\tvalid-rmse:5.32748\tvalid-mae:4.96512\n",
      "[500]\ttrain-rmse:0.56582\ttrain-mae:0.15744\tvalid-rmse:1.66081\tvalid-mae:1.01773\n",
      "[934]\ttrain-rmse:0.49956\ttrain-mae:0.12742\tvalid-rmse:1.65258\tvalid-mae:1.02354\n",
      "[0]\ttrain-rmse:4.01031\ttrain-mae:2.77329\tvalid-rmse:6.03824\tvalid-mae:5.67215\n",
      "[500]\ttrain-rmse:0.55785\ttrain-mae:0.15103\tvalid-rmse:1.31048\tvalid-mae:0.53260\n",
      "[619]\ttrain-rmse:0.53594\ttrain-mae:0.14061\tvalid-rmse:1.31466\tvalid-mae:0.53684\n",
      "[0]\ttrain-rmse:3.93150\ttrain-mae:2.68619\tvalid-rmse:6.16383\tvalid-mae:5.78339\n",
      "[500]\ttrain-rmse:0.54280\ttrain-mae:0.14366\tvalid-rmse:1.12190\tvalid-mae:0.47565\n",
      "[582]\ttrain-rmse:0.52610\ttrain-mae:0.13666\tvalid-rmse:1.11993\tvalid-mae:0.47583\n",
      "[0]\ttrain-rmse:3.86203\ttrain-mae:2.60889\tvalid-rmse:5.96223\tvalid-mae:5.38048\n",
      "[500]\ttrain-rmse:0.53651\ttrain-mae:0.14149\tvalid-rmse:0.96096\tvalid-mae:0.40664\n",
      "[939]\ttrain-rmse:0.46476\ttrain-mae:0.11194\tvalid-rmse:0.97816\tvalid-mae:0.40498\n",
      "[0]\ttrain-rmse:4.09246\ttrain-mae:2.89649\tvalid-rmse:6.64723\tvalid-mae:6.60457\n",
      "[500]\ttrain-rmse:0.52772\ttrain-mae:0.13912\tvalid-rmse:0.90137\tvalid-mae:0.51271\n",
      "[1000]\ttrain-rmse:0.44949\ttrain-mae:0.11058\tvalid-rmse:0.85968\tvalid-mae:0.49444\n",
      "[1500]\ttrain-rmse:0.39158\ttrain-mae:0.09101\tvalid-rmse:0.82542\tvalid-mae:0.48054\n",
      "[2000]\ttrain-rmse:0.34016\ttrain-mae:0.07545\tvalid-rmse:0.80941\tvalid-mae:0.47518\n",
      "[2299]\ttrain-rmse:0.31904\ttrain-mae:0.06804\tvalid-rmse:0.79953\tvalid-mae:0.47322\n",
      "[0]\ttrain-rmse:4.06273\ttrain-mae:2.84544\tvalid-rmse:5.19465\tvalid-mae:4.86201\n",
      "[490]\ttrain-rmse:0.52054\ttrain-mae:0.13268\tvalid-rmse:1.49253\tvalid-mae:0.96507\n",
      "[0]\ttrain-rmse:3.99723\ttrain-mae:2.76759\tvalid-rmse:6.03110\tvalid-mae:5.66863\n",
      "[500]\ttrain-rmse:0.52507\ttrain-mae:0.12997\tvalid-rmse:1.29192\tvalid-mae:0.50716\n",
      "[576]\ttrain-rmse:0.51035\ttrain-mae:0.12443\tvalid-rmse:1.29324\tvalid-mae:0.50783\n",
      "[0]\ttrain-rmse:3.92096\ttrain-mae:2.68193\tvalid-rmse:6.10130\tvalid-mae:5.72771\n",
      "[500]\ttrain-rmse:0.49860\ttrain-mae:0.12155\tvalid-rmse:1.22477\tvalid-mae:0.42189\n",
      "[1000]\ttrain-rmse:0.43123\ttrain-mae:0.09773\tvalid-rmse:1.20976\tvalid-mae:0.41823\n",
      "[1114]\ttrain-rmse:0.41995\ttrain-mae:0.09407\tvalid-rmse:1.20714\tvalid-mae:0.41817\n",
      "[0]\ttrain-rmse:3.84187\ttrain-mae:2.59909\tvalid-rmse:5.90346\tvalid-mae:5.33646\n",
      "[500]\ttrain-rmse:0.50630\ttrain-mae:0.12205\tvalid-rmse:0.95608\tvalid-mae:0.39299\n",
      "[604]\ttrain-rmse:0.48849\ttrain-mae:0.11554\tvalid-rmse:0.95652\tvalid-mae:0.39497\n",
      "[0]\ttrain-rmse:4.10959\ttrain-mae:2.90351\tvalid-rmse:6.29480\tvalid-mae:6.24413\n",
      "[500]\ttrain-rmse:0.56111\ttrain-mae:0.15471\tvalid-rmse:1.02438\tvalid-mae:0.41533\n",
      "[1000]\ttrain-rmse:0.47587\ttrain-mae:0.12127\tvalid-rmse:0.93928\tvalid-mae:0.39639\n",
      "[1500]\ttrain-rmse:0.42022\ttrain-mae:0.10060\tvalid-rmse:0.89390\tvalid-mae:0.39137\n",
      "[2000]\ttrain-rmse:0.37021\ttrain-mae:0.08416\tvalid-rmse:0.85967\tvalid-mae:0.38785\n",
      "[2500]\ttrain-rmse:0.33023\ttrain-mae:0.07138\tvalid-rmse:0.83481\tvalid-mae:0.38512\n",
      "[2681]\ttrain-rmse:0.31823\ttrain-mae:0.06752\tvalid-rmse:0.83361\tvalid-mae:0.38596\n",
      "[0]\ttrain-rmse:4.08484\ttrain-mae:2.85460\tvalid-rmse:5.33183\tvalid-mae:4.98050\n",
      "[500]\ttrain-rmse:0.55307\ttrain-mae:0.14892\tvalid-rmse:1.51672\tvalid-mae:0.99753\n",
      "[518]\ttrain-rmse:0.54942\ttrain-mae:0.14750\tvalid-rmse:1.51662\tvalid-mae:0.99814\n",
      "[0]\ttrain-rmse:4.00851\ttrain-mae:2.77173\tvalid-rmse:6.02163\tvalid-mae:5.65327\n",
      "[500]\ttrain-rmse:0.54329\ttrain-mae:0.14254\tvalid-rmse:1.18688\tvalid-mae:0.53434\n",
      "[649]\ttrain-rmse:0.51824\ttrain-mae:0.13194\tvalid-rmse:1.18664\tvalid-mae:0.53771\n",
      "[0]\ttrain-rmse:3.93028\ttrain-mae:2.68476\tvalid-rmse:6.14964\tvalid-mae:5.77087\n",
      "[500]\ttrain-rmse:0.53926\ttrain-mae:0.13913\tvalid-rmse:1.10820\tvalid-mae:0.43752\n",
      "[1000]\ttrain-rmse:0.46636\ttrain-mae:0.10983\tvalid-rmse:1.08874\tvalid-mae:0.42743\n",
      "[1258]\ttrain-rmse:0.44039\ttrain-mae:0.10035\tvalid-rmse:1.08234\tvalid-mae:0.42840\n",
      "[0]\ttrain-rmse:3.85433\ttrain-mae:2.60469\tvalid-rmse:5.96755\tvalid-mae:5.38818\n",
      "[500]\ttrain-rmse:0.52972\ttrain-mae:0.13521\tvalid-rmse:1.15465\tvalid-mae:0.47366\n",
      "[690]\ttrain-rmse:0.49924\ttrain-mae:0.12237\tvalid-rmse:1.15156\tvalid-mae:0.47323\n",
      "[0]\ttrain-rmse:4.12110\ttrain-mae:2.91012\tvalid-rmse:6.31383\tvalid-mae:6.26107\n",
      "[500]\ttrain-rmse:0.58523\ttrain-mae:0.16742\tvalid-rmse:0.94575\tvalid-mae:0.40908\n",
      "[931]\ttrain-rmse:0.51268\ttrain-mae:0.13631\tvalid-rmse:0.92281\tvalid-mae:0.40724\n",
      "[0]\ttrain-rmse:4.09674\ttrain-mae:2.86320\tvalid-rmse:5.29805\tvalid-mae:4.94109\n",
      "[500]\ttrain-rmse:0.57547\ttrain-mae:0.15792\tvalid-rmse:1.62268\tvalid-mae:0.98217\n",
      "[787]\ttrain-rmse:0.52814\ttrain-mae:0.13628\tvalid-rmse:1.61814\tvalid-mae:0.99480\n",
      "[0]\ttrain-rmse:4.01271\ttrain-mae:2.77506\tvalid-rmse:6.04425\tvalid-mae:5.67723\n",
      "[500]\ttrain-rmse:0.55604\ttrain-mae:0.15089\tvalid-rmse:1.26446\tvalid-mae:0.52638\n",
      "[597]\ttrain-rmse:0.53825\ttrain-mae:0.14280\tvalid-rmse:1.26737\tvalid-mae:0.52807\n",
      "[0]\ttrain-rmse:3.93633\ttrain-mae:2.68916\tvalid-rmse:6.17945\tvalid-mae:5.79637\n",
      "[500]\ttrain-rmse:0.53926\ttrain-mae:0.14261\tvalid-rmse:1.10157\tvalid-mae:0.48048\n",
      "[813]\ttrain-rmse:0.49289\ttrain-mae:0.12083\tvalid-rmse:1.09815\tvalid-mae:0.48201\n",
      "[0]\ttrain-rmse:3.85869\ttrain-mae:2.60749\tvalid-rmse:5.95293\tvalid-mae:5.37408\n",
      "[500]\ttrain-rmse:0.54265\ttrain-mae:0.14121\tvalid-rmse:1.00694\tvalid-mae:0.42660\n",
      "[995]\ttrain-rmse:0.45983\ttrain-mae:0.10792\tvalid-rmse:1.01951\tvalid-mae:0.42435\n",
      "[0]\ttrain-rmse:4.09501\ttrain-mae:2.89776\tvalid-rmse:6.68796\tvalid-mae:6.65132\n",
      "[500]\ttrain-rmse:0.52324\ttrain-mae:0.13928\tvalid-rmse:1.00446\tvalid-mae:0.57449\n",
      "[549]\ttrain-rmse:0.51382\ttrain-mae:0.13517\tvalid-rmse:0.99866\tvalid-mae:0.57480\n",
      "[0]\ttrain-rmse:4.06873\ttrain-mae:2.84935\tvalid-rmse:5.34701\tvalid-mae:4.97923\n",
      "[500]\ttrain-rmse:0.51336\ttrain-mae:0.13190\tvalid-rmse:1.53666\tvalid-mae:0.96408\n",
      "[559]\ttrain-rmse:0.50082\ttrain-mae:0.12726\tvalid-rmse:1.53730\tvalid-mae:0.96847\n",
      "[0]\ttrain-rmse:3.99817\ttrain-mae:2.76889\tvalid-rmse:5.97932\tvalid-mae:5.61569\n",
      "[500]\ttrain-rmse:0.51177\ttrain-mae:0.12691\tvalid-rmse:1.23305\tvalid-mae:0.49338\n",
      "[554]\ttrain-rmse:0.50069\ttrain-mae:0.12277\tvalid-rmse:1.22841\tvalid-mae:0.49389\n",
      "[0]\ttrain-rmse:3.92293\ttrain-mae:2.68401\tvalid-rmse:6.11228\tvalid-mae:5.73994\n",
      "[500]\ttrain-rmse:0.49963\ttrain-mae:0.12052\tvalid-rmse:1.21264\tvalid-mae:0.41346\n",
      "[919]\ttrain-rmse:0.44405\ttrain-mae:0.10083\tvalid-rmse:1.20013\tvalid-mae:0.41365\n",
      "[0]\ttrain-rmse:3.84941\ttrain-mae:2.60494\tvalid-rmse:5.96746\tvalid-mae:5.39441\n",
      "[500]\ttrain-rmse:0.50149\ttrain-mae:0.12000\tvalid-rmse:0.97635\tvalid-mae:0.40631\n",
      "[767]\ttrain-rmse:0.45915\ttrain-mae:0.10503\tvalid-rmse:0.97562\tvalid-mae:0.40973\n",
      "[0]\ttrain-rmse:4.11711\ttrain-mae:2.90939\tvalid-rmse:6.33139\tvalid-mae:6.28064\n",
      "[500]\ttrain-rmse:0.56566\ttrain-mae:0.16020\tvalid-rmse:1.00295\tvalid-mae:0.42854\n",
      "[1000]\ttrain-rmse:0.48801\ttrain-mae:0.12714\tvalid-rmse:0.95636\tvalid-mae:0.41511\n",
      "[1500]\ttrain-rmse:0.42846\ttrain-mae:0.10441\tvalid-rmse:0.90768\tvalid-mae:0.40577\n",
      "[2000]\ttrain-rmse:0.37829\ttrain-mae:0.08697\tvalid-rmse:0.88230\tvalid-mae:0.40420\n",
      "[2101]\ttrain-rmse:0.36848\ttrain-mae:0.08404\tvalid-rmse:0.87539\tvalid-mae:0.40317\n",
      "[0]\ttrain-rmse:4.08314\ttrain-mae:2.85611\tvalid-rmse:5.33849\tvalid-mae:4.98232\n",
      "[500]\ttrain-rmse:0.55411\ttrain-mae:0.15124\tvalid-rmse:1.48031\tvalid-mae:1.07878\n",
      "[945]\ttrain-rmse:0.48189\ttrain-mae:0.12195\tvalid-rmse:1.46081\tvalid-mae:1.07450\n",
      "[0]\ttrain-rmse:4.01385\ttrain-mae:2.77551\tvalid-rmse:6.02161\tvalid-mae:5.64274\n",
      "[500]\ttrain-rmse:0.54178\ttrain-mae:0.14278\tvalid-rmse:1.19982\tvalid-mae:0.52924\n",
      "[589]\ttrain-rmse:0.52571\ttrain-mae:0.13583\tvalid-rmse:1.20920\tvalid-mae:0.53176\n",
      "[0]\ttrain-rmse:3.94503\ttrain-mae:2.69633\tvalid-rmse:6.18549\tvalid-mae:5.80280\n",
      "[500]\ttrain-rmse:0.53461\ttrain-mae:0.13683\tvalid-rmse:1.12094\tvalid-mae:0.44986\n",
      "[1000]\ttrain-rmse:0.46914\ttrain-mae:0.10926\tvalid-rmse:1.09523\tvalid-mae:0.44346\n",
      "[1356]\ttrain-rmse:0.43265\ttrain-mae:0.09673\tvalid-rmse:1.08147\tvalid-mae:0.44287\n",
      "[0]\ttrain-rmse:3.86570\ttrain-mae:2.61231\tvalid-rmse:5.99187\tvalid-mae:5.41883\n",
      "[500]\ttrain-rmse:0.53361\ttrain-mae:0.13557\tvalid-rmse:1.13885\tvalid-mae:0.47870\n",
      "[935]\ttrain-rmse:0.46451\ttrain-mae:0.10846\tvalid-rmse:1.15354\tvalid-mae:0.47987\n",
      "[0]\ttrain-rmse:4.12099\ttrain-mae:2.91101\tvalid-rmse:6.29916\tvalid-mae:6.24725\n",
      "[500]\ttrain-rmse:0.59084\ttrain-mae:0.16896\tvalid-rmse:0.89061\tvalid-mae:0.41808\n",
      "[1000]\ttrain-rmse:0.51045\ttrain-mae:0.13341\tvalid-rmse:0.85489\tvalid-mae:0.41284\n",
      "[1500]\ttrain-rmse:0.45364\ttrain-mae:0.11158\tvalid-rmse:0.84317\tvalid-mae:0.41304\n",
      "[1566]\ttrain-rmse:0.44766\ttrain-mae:0.10939\tvalid-rmse:0.84074\tvalid-mae:0.41340\n",
      "[0]\ttrain-rmse:4.08432\ttrain-mae:2.85552\tvalid-rmse:5.38998\tvalid-mae:5.02743\n",
      "[500]\ttrain-rmse:0.56995\ttrain-mae:0.15789\tvalid-rmse:1.58524\tvalid-mae:1.10822\n",
      "[970]\ttrain-rmse:0.49389\ttrain-mae:0.12521\tvalid-rmse:1.57943\tvalid-mae:1.11434\n",
      "[0]\ttrain-rmse:4.01387\ttrain-mae:2.77555\tvalid-rmse:6.03933\tvalid-mae:5.67313\n",
      "[500]\ttrain-rmse:0.54842\ttrain-mae:0.14840\tvalid-rmse:1.29109\tvalid-mae:0.54213\n",
      "[555]\ttrain-rmse:0.53769\ttrain-mae:0.14324\tvalid-rmse:1.30220\tvalid-mae:0.54719\n",
      "[0]\ttrain-rmse:3.93329\ttrain-mae:2.68688\tvalid-rmse:6.16730\tvalid-mae:5.78582\n",
      "[500]\ttrain-rmse:0.54965\ttrain-mae:0.14565\tvalid-rmse:1.09703\tvalid-mae:0.47991\n",
      "[572]\ttrain-rmse:0.53413\ttrain-mae:0.13854\tvalid-rmse:1.09812\tvalid-mae:0.47875\n",
      "[0]\ttrain-rmse:3.85692\ttrain-mae:2.60610\tvalid-rmse:5.94449\tvalid-mae:5.36412\n",
      "[500]\ttrain-rmse:0.53766\ttrain-mae:0.14174\tvalid-rmse:0.97860\tvalid-mae:0.41680\n",
      "[1000]\ttrain-rmse:0.45503\ttrain-mae:0.10784\tvalid-rmse:0.98681\tvalid-mae:0.41739\n",
      "[1061]\ttrain-rmse:0.44668\ttrain-mae:0.10472\tvalid-rmse:0.99104\tvalid-mae:0.41871\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "fair_constant = 1\n",
    "def fair_obj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    x = (preds - labels)\n",
    "    den = abs(x) + fair_constant\n",
    "    grad = fair_constant * x / (den)\n",
    "    hess = fair_constant * fair_constant / (den * den)\n",
    "    return grad, hess\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    # return a pair metric_name, result. The metric name must not contain a colon (:) or a space\n",
    "    # since preds are margin(before logistic transformation, cutoff at 0)\n",
    "    return 'mae', np.mean(np.abs(preds-labels))\n",
    "\n",
    "oof_predictions['oof2'] = 0\n",
    "xgb_models = []\n",
    "df_test['label2'] = 0\n",
    "seedlist = [3333+i**2 for i in range(5)]\n",
    "monthlist = [40, 41, 42]\n",
    "\n",
    "for seed in seedlist:\n",
    "    \n",
    "    xgb_params = {\n",
    "            'booster': 'gbtree',\n",
    "            'tree_method': 'hist',\n",
    "            'max_depth': 5,\n",
    "            'eta': 0.02,   \n",
    "            'subsample':0.95,\n",
    "            'colsample_bytree':0.95,\n",
    "            'random_state': seed,\n",
    "            'nthread': 4,\n",
    "        }\n",
    "\n",
    "\n",
    "    \n",
    "    df_test['pred2'] = 0\n",
    "    for shift, test_month in enumerate(monthlist):\n",
    "        df = pd.concat([df_train.copy(), df_test.copy()])\n",
    "        df = getFE(df, shift=shift)\n",
    "        \n",
    "        df = getFirstMonth(df)\n",
    "        \n",
    "        df_train_ = df[df['label_sum'].notna()].reset_index(drop=True)\n",
    "        df_test_ = df[df['label_sum'].isna()].reset_index(drop=True)\n",
    "        \n",
    "#         df_train_,df_test_ = target_encode(df_train_, df_test_)\n",
    "        \n",
    "        not_use = ['product_id']\n",
    "        # cate_features = ['product_id','type']\n",
    "        features = [c for c in df_test_.columns if c not in ['start_sale', 'pred1','label1', 'pred2', 'label2', 'date','year','label_sum', 'season', 'month', 'time']+not_use]\n",
    "        label = ['label_sum']\n",
    "        df_train_[label] = np.log1p(df_train_[label])\n",
    "        \n",
    "        X_tr_val = df_train_.copy()\n",
    "        X_te     = df_test_.loc[df_test_.time == test_month, features]\n",
    "        dtest = xgb.DMatrix(data=X_te, label=None)\n",
    "        \n",
    "        kfold = 5\n",
    "        for fold in range(kfold):\n",
    "\n",
    "            X_train,X_valid = X_tr_val.loc[X_tr_val.time < (39-fold), features], X_tr_val.loc[X_tr_val.time == (39-fold), features]\n",
    "            y_train,y_valid = X_tr_val.loc[X_tr_val.time < (39-fold), label], X_tr_val.loc[X_tr_val.time == (39-fold), label]\n",
    "        \n",
    "            dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "            dvalid = xgb.DMatrix(data=X_valid, label=y_valid)\n",
    "            model_mae = xgb.train(xgb_params, \n",
    "                    dtrain=dtrain,\n",
    "                    evals=[(dtrain,'train'),(dvalid,'valid')],\n",
    "                    num_boost_round=5000,\n",
    "                    early_stopping_rounds=250,\n",
    "                    verbose_eval=500,\n",
    "                    obj = fair_obj,\n",
    "                    feval = evalerror,\n",
    "                ) \n",
    "        \n",
    "            df_test.loc[df_test.time == test_month, 'pred2'] += model_mae.predict(dtest) / kfold\n",
    "            \n",
    "            oof_predictions.loc[oof_predictions.time == (39-fold), 'oof2'] += model_mae.predict(dvalid) / len(seedlist) / len(monthlist)\n",
    "\n",
    "    df_test['label2'] += df_test['pred2'] / len(seedlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c6cc5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.741147089553128"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_month = 35\n",
    "scores = evalScore(oof_predictions[oof_predictions.time>=test_month].reset_index(drop=True), oof_predictions.loc[oof_predictions.time>=test_month,'oof2'].reset_index(drop=True))\n",
    "scores\n",
    "\n",
    "# 0.7255152028206725 rm 2feat 0.7327147870156067"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20284ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import catboost as cb \n",
    "\n",
    "# oof_predictions['oof3'] = 0\n",
    "# df_test['label3'] = 0\n",
    "# seedlist = [3333+i**2 for i in range(1)]\n",
    "# monthlist = [40, 41, 42]\n",
    "\n",
    "# for seed in seedlist:\n",
    "    \n",
    "#     cat_params = {\n",
    "#         'learning_rate': 0.02,\n",
    "#         'loss_function': \"MAE\",\n",
    "#         'eval_metric': \"MAE\",\n",
    "#         'grow_policy': 'Depthwise',\n",
    "#         'depth': 5,\n",
    "#         'subsample': 0.95, \n",
    "#         'rsm': 0.95,\n",
    "#         'random_seed': seed,\n",
    "#         'one_hot_max_size': 3,   #类别数量多于此数将使用ordered target statistics编码方法,默认值为2。\n",
    "#         'boosting_type':\"Plain\", #Ordered 或者Plain,数据量较少时建议使用Ordered,训练更慢但能够缓解梯度估计偏差。\n",
    "#         'max_ctr_complexity': 1, #特征组合的最大特征数量，设置为1取消特征组合，设置为2只做两个特征的组合,默认为4。\n",
    "#         'metric_period': 500,\n",
    "#         'thread_count': 4,\n",
    "#         'iterations': 5000,\n",
    "#         'od_wait': 100,\n",
    "#     }\n",
    "\n",
    "\n",
    "    \n",
    "#     df_test['pred3'] = 0\n",
    "#     for shift, test_month in enumerate(monthlist):\n",
    "#         df = pd.concat([df_train.copy(), df_test.copy()])\n",
    "#         df = getFE(df, shift=shift)\n",
    "#         df_train_ = df[df['label_sum'].notna()].reset_index(drop=True)\n",
    "#         df_test_ = df[df['label_sum'].isna()].reset_index(drop=True)\n",
    "        \n",
    "#         not_use = ['product_id']\n",
    "        \n",
    "# #         cate_features = ['type']\n",
    "# #         for col in cate_features:\n",
    "# #             df_train_[col] = pd.Categorical(df_train_[col]) \n",
    "# #             df_test_[col] = pd.Categorical(df_test_[col]) \n",
    "            \n",
    "#         features = [c for c in df_test_.columns if c not in ['date','year','label_sum', 'season', 'month', 'time']+not_use]\n",
    "#         label = ['label_sum']\n",
    "#         df_train_[label] = np.log1p(df_train_[label])\n",
    "        \n",
    "#         X_tr_val = df_train_.copy()\n",
    "#         X_te     = df_test_.loc[df_test_.time == test_month, features]\n",
    "        \n",
    "#         kfold = 5\n",
    "#         for fold in range(kfold):\n",
    "\n",
    "#             X_train,X_valid = X_tr_val.loc[X_tr_val.time < (39-fold), features], X_tr_val.loc[X_tr_val.time == (39-fold), features]\n",
    "#             y_train,y_valid = X_tr_val.loc[X_tr_val.time < (39-fold), label], X_tr_val.loc[X_tr_val.time == (39-fold), label]\n",
    "        \n",
    "#             model = cb.CatBoostRegressor(\n",
    "#                 **cat_params\n",
    "#             )\n",
    "            \n",
    "#             model.fit(X_train, y_train,\n",
    "#              eval_set=(X_valid,y_valid),\n",
    "# #              cat_features=cate_features,\n",
    "#              use_best_model=True,\n",
    "#              verbose=True)\n",
    "\n",
    "            \n",
    "#             df_test.loc[df_test.time == test_month, 'pred3'] += model.predict(X_te) / kfold\n",
    "            \n",
    "#             oof_predictions.loc[oof_predictions.time == (39-fold), 'oof3'] += model_mae.predict(dvalid) / len(seedlist) / len(monthlist)\n",
    "\n",
    "#     df_test['label3'] += df_test['pred3'] / len(seedlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9c5c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_month = 35\n",
    "# scores = evalScore(oof_predictions[oof_predictions.time>=test_month].reset_index(drop=True), oof_predictions.loc[oof_predictions.time>=test_month,'oof3'].reset_index(drop=True))\n",
    "# scores\n",
    "\n",
    "# 0.7255152028206725 rm 2feat 0.7327147870156067"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ea95926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.743693330325175\n",
      "0.2 0.7460330535670383\n",
      "0.3 0.7476087030806785\n",
      "0.4 0.7489239060039423\n",
      "0.5 0.7499697402960133\n",
      "0.6 0.7509171389604813\n",
      "0.7 0.7511029564753006\n",
      "0.8 0.7510113253200797\n",
      "0.9 0.7506437959575352\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    oof_predictions['oof_ensemble'] = (oof_predictions['oof1']*(i/10) + oof_predictions['oof2']*(1-i/10))\n",
    "    scores = evalScore(X_tr_val[X_tr_val.time>=test_month].reset_index(drop=True), oof_predictions.loc[oof_predictions.time>=test_month,'oof_ensemble'].reset_index(drop=True))\n",
    "    print(i/10, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0c1e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'] = df_test['label1']*0.5+df_test['label2']*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6aedb1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.loc[df_test.product_id.isin(zero_product), 'label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71064eba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scores = ifly_metric(X_tr_val.loc[X_tr_val.time>=test_month,label].values.T, oof_predictions.loc[oof_predictions.time>=test_month,'oof'].values)\n",
    "# print('oof score: ', scores)\n",
    "# plt.plot(np.expm1((X_tr_val.loc[X_tr_val.time>=test_month,label].values.T).T))\n",
    "# plt.plot(np.expm1(oof_predictions.loc[oof_predictions.time>=test_month,'oof'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933e6ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6358e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline 1fold 0.5738199939337411 5fold 0.5807842667667733  LB 0.55043\n",
    "# 1fold 0.7068198452363535 5fold 0.7135140090324157 LB 0.672\n",
    "# 1fold 0.7477 LB 0.681"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33bb2557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oof_prediction(X_, y):\n",
    "    X = df_train.copy()\n",
    "    X[features] = X_\n",
    "#     for i, col in enumerate(features):\n",
    "#         X[col] = X_[:,i]\n",
    "    oof_ = X.copy()\n",
    "    oof_['oof'] = 0\n",
    "    \n",
    "    models = lgb_models\n",
    "    seed = 3333\n",
    "    kf = GroupKFold(n_splits=N_FOLDS)\n",
    "    test_month = 25\n",
    "    group_ids = X['product_id']\n",
    "    random.seed(seed)\n",
    "    random.shuffle(group_ids)\n",
    "    \n",
    "    for f,(tr_ind,val_ind) in enumerate(kf.split(X[features], X[label], groups=group_ids)):\n",
    "        X_train,X_valid = X.iloc[tr_ind][features], X.iloc[val_ind][features]\n",
    "        y_train,y_valid = X.iloc[tr_ind][label], X.iloc[val_ind][label]\n",
    "        \n",
    "        pre9 = (X.iloc[val_ind]['time'] < test_month)\n",
    "        inv3 = (X.iloc[val_ind]['time'] >= test_month)\n",
    "        X_train, y_train= pd.concat([X_train, X_valid[pre9]]).reset_index(drop=True), pd.concat([y_train, y_valid[pre9]]).reset_index(drop=True)\n",
    "        X_valid, y_valid = X_valid[inv3], y_valid[inv3]\n",
    "        oof_.loc[oof_.iloc[val_ind][inv3].index, 'oof'] = models[f].predict(X_valid)\n",
    "    oof_score = evalScore(X[X.time>=test_month].reset_index(drop=True), oof_.loc[oof_.time>=test_month,'oof'].reset_index(drop=True))\n",
    "    print(oof_score)\n",
    "    return oof_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ec1f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from eli5.permutation_importance import get_score_importances\n",
    "\n",
    "# def score(X, y):\n",
    "# #     y_pred = lgb_models[-1].predict(X)\n",
    "# #     return ifly_metric(y, y_pred)\n",
    "#     return oof_prediction(X, y)\n",
    "\n",
    "# base_score, score_decreases = get_score_importances(score, df_train[features].values, df_train[label].values, n_iter=1)\n",
    "\n",
    "# threshold = 0.001\n",
    "# bad_features = df_train[features].columns[-score_decreases[0] > threshold]\n",
    "# bad_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "decc1019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 特征重要性\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['feature'] = features\n",
    "feature_importances['gain'] = 0\n",
    "for model in lgb_models:\n",
    "    \n",
    "#     importance_type='gain'\n",
    "    feature_importances['gain'] += model.feature_importance(importance_type='gain') / N_FOLDS / len(seedlist)\n",
    "\n",
    "best_features = feature_importances.sort_values(by='gain', ascending=False)[:40]\n",
    "plt.figure(figsize=(16, 12));\n",
    "sns.barplot(x=\"gain\", y=\"feature\", data=best_features);\n",
    "plt.title('LGB Features (avg over folds)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b01afa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[24]:\n",
    "\n",
    "\n",
    "feature_importances.sort_values(by='gain', ascending=False).to_csv('fea_imp.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9985be2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                          feature  gain\n",
       " 0                 is_sale_day_sum     0\n",
       " 17                    end_stock_1     0\n",
       " 31     product_id_stock_diff_mean     0\n",
       " 30                    label_sum_5     0\n",
       " 29                    label_sum_4     0\n",
       " 28                    label_sum_3     0\n",
       " 27                    end_stock_3     0\n",
       " 26                  start_stock_3     0\n",
       " 25                        order_3     0\n",
       " 24                    stock_sum_3     0\n",
       " 23                   stock_diff_3     0\n",
       " 22                    end_stock_2     0\n",
       " 21                  start_stock_2     0\n",
       " 20                        order_2     0\n",
       " 19                    stock_sum_2     0\n",
       " 18                   stock_diff_2     0\n",
       " 16                  start_stock_1     0\n",
       " 1               is_sale_day_count     0\n",
       " 15                        order_1     0\n",
       " 14                    stock_sum_1     0\n",
       " 13                   stock_diff_1     0\n",
       " 12               order_sale_ratio     0\n",
       " 11  product_year_stock_diff_ratio     0\n",
       " 10          type_stock_diff_ratio     0\n",
       " 9     product_year_stock_diff_sum     0\n",
       " 8             type_stock_diff_sum     0\n",
       " 7                       stock_sum     0\n",
       " 6                      stock_diff     0\n",
       " 5                       end_stock     0\n",
       " 4                     start_stock     0\n",
       " 3                           order     0\n",
       " 2                            type     0\n",
       " 32           type_stock_diff_mean     0,\n",
       "                           feature  gain\n",
       " 0                 is_sale_day_sum     0\n",
       " 17                    end_stock_1     0\n",
       " 31     product_id_stock_diff_mean     0\n",
       " 30                    label_sum_5     0\n",
       " 29                    label_sum_4     0\n",
       " 28                    label_sum_3     0\n",
       " 27                    end_stock_3     0\n",
       " 26                  start_stock_3     0\n",
       " 25                        order_3     0\n",
       " 24                    stock_sum_3     0\n",
       " 23                   stock_diff_3     0\n",
       " 22                    end_stock_2     0\n",
       " 21                  start_stock_2     0\n",
       " 20                        order_2     0\n",
       " 19                    stock_sum_2     0\n",
       " 18                   stock_diff_2     0\n",
       " 16                  start_stock_1     0\n",
       " 1               is_sale_day_count     0\n",
       " 15                        order_1     0\n",
       " 14                    stock_sum_1     0\n",
       " 13                   stock_diff_1     0\n",
       " 12               order_sale_ratio     0\n",
       " 11  product_year_stock_diff_ratio     0\n",
       " 10          type_stock_diff_ratio     0\n",
       " 9     product_year_stock_diff_sum     0\n",
       " 8             type_stock_diff_sum     0\n",
       " 7                       stock_sum     0\n",
       " 6                      stock_diff     0\n",
       " 5                       end_stock     0\n",
       " 4                     start_stock     0\n",
       " 3                           order     0\n",
       " 2                            type     0\n",
       " 32           type_stock_diff_mean     0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[25]:\n",
    "\n",
    "\n",
    "feature_importances.sort_values(by='gain', ascending=False)[-100:].feature.values\n",
    "feature_importances.sort_values(by='gain', ascending=False)[-50:], feature_importances.sort_values(by='gain', ascending=False)[:50]\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8f44e9",
   "metadata": {},
   "source": [
    "#### 提交结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b61ad9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "df_test['label'] = np.expm1(df_test['label'])\n",
    "df_submit = df_test[['date','product_id','label']].copy()\n",
    "df_submit.rename(columns = {'date':'month'},inplace = True)\n",
    "df_submit['label'] = df_submit['label'].map(lambda x: x if x >= 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "185c436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[27]:\n",
    "\n",
    "\n",
    "df_submit[['month','product_id','label']].to_csv(f'timesplit_{scores}.csv',index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4802678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In[28]:\n",
    "\n",
    "\n",
    "df_submit['label'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a51c9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD7CAYAAAB0d9PAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAr5ElEQVR4nO3deZxcVZ338c+vu7PvSxMxARIkokFxgDwhguKChoDzEh9FHxgVRDTjiOMyixPEIW4oqCPLDIIMwQCyGkEiCYSs7AnpkH3v7Gt3J52kk+50ejvPH3Wq+3Z1VXWna7lV3d/369Wv3Dp1q+4vVbfu757lnmvOOURERBIpCDsAERHJbUoUIiKSlBKFiIgkpUQhIiJJKVGIiEhSShQiIpJUu4nCzB42s3IzWxsoG2pm88xsi/93iC83M7vXzErNbLWZXRh4zQ1+/S1mdkOg/CIzW+Nfc6+ZWbJtiIhIdnWkRjEDmBxTNhVY4JwbCyzwjwGuBMb6vynA/RA56APTgIuBCcC0wIH/fuCbgddNbmcbIiKSRdaRC+7MbDTwgnPuA/7xJuDjzrn9ZnY6sNg5d66Z/cEvPxlcL/rnnPtHX/4HYLH/W+Sce58vvy66XqJttBfr8OHD3ejRozv+CYiICMuXLz/onCuO91xRJ99zhHNuv18+AIzwyyOB3YH19viyZOV74pQn20ZSo0ePpqSkpIP/DRERATCznYmeS7kz20WqJBmdB6S9bZjZFDMrMbOSioqKTIYiItLtdDZRlPnmIPy/5b58L3BGYL1RvixZ+ag45cm20YZz7kHn3Hjn3Pji4rg1JxER6aTOJopZQHTk0g3A84Hy6/3op4nAUd98NBeYZGZDfCf2JGCuf67KzCb60U7Xx7xXvG2IiEgWtdtHYWZPEumMHm5me4iMXroDeMbMbgJ2Al/yq88BrgJKgRrgRgDnXKWZ/RxY5tf7mXOu0i9/m8jIqj7Ai/6PJNsQEZEs6tCop3wyfvx4p85sEZFTY2bLnXPj4z2nK7NFRCQpJQoREUlKiULywqxV+zh6oj7sMES6JSUKyXml5cf47pMr+Lc/rwo7FJFuSYlCct6JuiYA9h89EXIkIt2TEoXkPJfZC/9FpB1KFCIikpQShYiIJKVEIXnDsLBDEOmWlChERCQpJQoREUlKiUJyXhebjkwk7yhRiIhIUkoUIiKSlBKF5A3ToCeRUChRiIhIUkoUIiKSlBKF5DwNehIJlxKF5A11UYiEQ4lCRESSUqIQEZGklCgk5zldmi0SKiUKERFJSolCRESSUqKQ/KFLs0VCoUQhIiJJKVGIiEhSShQiIpKUEoWIiCSlRCEiIkkpUUjO0+V2IuFSohARkaRSShRm9gMzW2dma83sSTPrbWZjzGypmZWa2dNm1tOv28s/LvXPjw68zy2+fJOZXREon+zLSs1saiqxiohI53Q6UZjZSOC7wHjn3AeAQuBa4E7gLufcOcBh4Cb/kpuAw778Lr8eZjbOv+48YDLwezMrNLNC4D7gSmAccJ1fV7opXW4nEo5Um56KgD5mVgT0BfYDnwRm+ucfAT7nl6/2j/HPX25m5sufcs6ddM5tB0qBCf6v1Dm3zTlXBzzl15VuSn0VIuHodKJwzu0FfgvsIpIgjgLLgSPOuQa/2h5gpF8eCez2r23w6w8Llse8JlG5dFOqUYiEI5WmpyFEzvDHAO8G+hFpOso6M5tiZiVmVlJRURFGCJJBmmVcJFypND19CtjunKtwztUDzwKXAoN9UxTAKGCvX94LnAHgnx8EHAqWx7wmUXkbzrkHnXPjnXPji4uLU/gvSS7TnIAi4UglUewCJppZX9/XcDmwHlgEXOPXuQF43i/P8o/xzy90kTvSzAKu9aOixgBjgbeBZcBYP4qqJ5EO71kpxCt5S1UKkTAVtb9KfM65pWY2E3gHaABWAA8Cs4GnzOwXvmy6f8l04DEzKwUqiRz4cc6tM7NniCSZBuBm51wjgJl9B5hLZETVw865dZ2NV0REOqfTiQLAOTcNmBZTvI3IiKXYdWuBLyZ4n9uB2+OUzwHmpBKjiIikRldmS07705KdXPPAW4BGPYmEJaUahUim/fiva8MOQaTbU41CRESSUqIQSZOGxqawQxDJCCUKyRuWwxdSrNlzlHNufZHFm8rDDkUk7ZQoRNLgnV2HAVi0UYlCuh4lCpE0KCiI1Hbqm3RxoHQ9ShQiaeDzhOalki5JiULyRu72UMDcdWUAVFafDDkSkfRTohBJg1c3R2Yt3lx2PORIRNJPiUIkjZzanqQLUqIQSSOlCemKlCgkb+TwZRQiXZoShUgaqeVJuiIlCskbltPjniKcGp+kC1KiEBGRpJQoREQkKSUKERFJSolC8kfud1GoM1u6JCUKyR95cBA+UdcYdggiaadEIZJGh6rrwg5BJO2UKCR/5EHT08Deug29dD1KFCJplMt34RPpLCUKkTRqUm+2dEFKFCLppDwhXZASheSNfGjUUZ6QrkiJQiQNLnnPMAA+fm5xyJGIpJ8ShUgafHDUIADOe/egkCMRST8lCpF0UJuTdGFKFJI3NPJUJBxKFCLpoCQmXZgSheQN3bhIJBxKFCIiklRKicLMBpvZTDPbaGYbzOzDZjbUzOaZ2Rb/7xC/rpnZvWZWamarzezCwPvc4NffYmY3BMovMrM1/jX3muZHEBHJulRrFPcALznn3gd8CNgATAUWOOfGAgv8Y4ArgbH+bwpwP4CZDQWmARcDE4Bp0eTi1/lm4HWTU4xXJCPyoVlMpLM6nSjMbBBwGTAdwDlX55w7AlwNPOJXewT4nF++GnjURSwBBpvZ6cAVwDznXKVz7jAwD5jsnxvonFvinHPAo4H3km5I9UmRcKRSoxgDVAB/NLMVZvaQmfUDRjjn9vt1DgAj/PJIYHfg9Xt8WbLyPXHK2zCzKWZWYmYlFRUVKfyXREQkViqJogi4ELjfOXcBUE1LMxMAviaQ8WEgzrkHnXPjnXPji4s1hYKISDqlkij2AHucc0v945lEEkeZbzbC/1vun98LnBF4/Shflqx8VJxykZylWcalK+p0onDOHQB2m9m5vuhyYD0wC4iOXLoBeN4vzwKu96OfJgJHfRPVXGCSmQ3xndiTgLn+uSozm+hHO10feC/phtRHIRKOVO/b+M/A42bWE9gG3Egk+TxjZjcBO4Ev+XXnAFcBpUCNXxfnXKWZ/RxY5tf7mXOu0i9/G5gB9AFe9H8iIpJFKSUK59xKYHycpy6Ps64Dbk7wPg8DD8cpLwE+kEqMItmg2k72VJ9soLqugdMG9A47lG5DV2aLSF75zL2vMeH2BWGH0a0oUUje0EVtArDjUE3YIXQ7ShQiIpKUEoVIGqiuI12ZEoVIGjldSCFdkBKF5A2NLBIJhxKFSBppJnzpipQoRNJITU/SFSlRiKSBKhLSlSlRiIhIUkoUIpKXausbww6h21CiEEkjdVFkz+JNuklZtihRiKSBpheRrkyJQkTylKpv2aJEIXlD1yiIhEOJQiSNdI4rXZEShUgaqLIjXZkShUgaaLRT9ukzzx4lCskbOmmXoANVtaFu/4sPvMnku18NNYZsUaIQSQM1PWXfT/+2PtTtL9txmI0HjoW2/d2VNby09kBWtqVEIZJGag6RbLnyntf41p+WZ2VbShQiInno+MmGrG1LiULyhpp3RMKhRCGSBsph0pUpUYiISFJKFCIikpQSheQNNe+IhEOJQiSNnGZ7ki5IiUJERJJSohARkaSUKCRv5PT9KHI5ti7q+g+fFXYI3YYShUgaaQqP7Bnct2fYIXQbKScKMys0sxVm9oJ/PMbMlppZqZk9bWY9fXkv/7jUPz868B63+PJNZnZFoHyyLys1s6mpxioi0hUcrq7L6vbSUaP4HrAh8PhO4C7n3DnAYeAmX34TcNiX3+XXw8zGAdcC5wGTgd/75FMI3AdcCYwDrvPrioh0a5+597Wsbi+lRGFmo4DPAA/5xwZ8EpjpV3kE+Jxfvto/xj9/uV//auAp59xJ59x2oBSY4P9KnXPbnHN1wFN+XemmcrkXIJdj67K6cTvfvqPZvRdHqjWKu4EfAk3+8TDgiHMuOq3hHmCkXx4J7Abwzx/16zeXx7wmUXkbZjbFzErMrKSioiLF/5JI53XfQ5d0ZZ1OFGb290C5cy47E6In4Zx70Dk33jk3vri4OOxwJEM0sEiCpr++HdeNaxXZlEqN4lLgs2a2g0iz0CeBe4DBZlbk1xkF7PXLe4EzAPzzg4BDwfKY1yQqF8lZymXZU13XyOLNakHIhk4nCufcLc65Uc650UQ6oxc6574MLAKu8avdADzvl2f5x/jnF7rI6cAs4Fo/KmoMMBZ4G1gGjPWjqHr6bczqbLwi2aDz2+w6Wd/U/kqSsqL2Vzll/wE8ZWa/AFYA0335dOAxMysFKokc+HHOrTOzZ4D1QANws3OuEcDMvgPMBQqBh51z6zIQr0jK1CwWFqXmbEhLonDOLQYW++VtREYsxa5TC3wxwetvB26PUz4HmJOOGKUr0NFYJAy6MlvyiM4eJZZOHrJBiUIknTQKR7ogJQrJI7l79mg5HFvXpsScDUoUIiJ55GRDY9a3qUQhInms+9XkauuyPyRYiUIkjdQQkll7j5yIKel+n3hBCEdtJQrJG7l8rUIux9aV1DXoAruCEHY2JQqRNNBgJ8mWMHY1JQoRkTwSxkSIShQiaaCmp+yI/Zi7Y01ONQqRJPLhWNwdD1xh6o4JOnYfy0YNQ4kiA8677SW+/Xjot+kQ6fK6ZWJukygyv0kligyormtkzpoDYYfR5XTHs0dJrnvmCfVRiOQl5TDJljZNT1nYphKFiOQN1Sph/f6qVo/VRyEiksT6fVXtr9TFfPmhpa0eq0YhEmAYjU2Ou+dvpqq2PuxwJAf8z6LSULYbxrUMiagzWyTG3HUHuHv+Fn45e0PYocQVRkdjd6Lp3MOhRCF5pb4xMtdPTV32p1oWiYp3Fl/X0MTCjWXZjyULJydKFCIipyjeofk3czfy9RklLN12KLuxqOlJpEUuj3jJ5dgkO3YeqgHgcE3m+s9OhFSTVqIQSaMc6uOUDAqrMzteM5NqFCIiWbK14jgHj5/s0Lrd7XxAiUJE8kYmm/gu/69X+MidCzO3gTSIV3tQZ7ZIQPAgkWtndKZOii6htr5jd9DLpSZGNT2J5JkcOn5IBoV1vUy8rerKbBGRdvxpyc6wQwiV5noSyTNqgMq+H/91bda3GVbTU1ijrZQoJG/kw/QNv1+8lSmPloQdhoQgG4dwNT2JdBEvr8/+NA7SfakzOw/l0qySXVmufc65Fo9kVryvOxv13bi7mRJF/mnS8SKjNAxVJPs6nSjM7AwzW2Rm681snZl9z5cPNbN5ZrbF/zvEl5uZ3WtmpWa22swuDLzXDX79LWZ2Q6D8IjNb419zr+XBUaJJZ5aZk/PfvmRarhwB4k6lkZ0NxynK7VFPDcC/OufGAROBm81sHDAVWOCcGwss8I8BrgTG+r8pwP0QSSzANOBiYAIwLZpc/DrfDLxucgrxZoXyhEjm5MrvK3nTU+aCzLu5npxz+51z7/jlY8AGYCRwNfCIX+0R4HN++WrgURexBBhsZqcDVwDznHOVzrnDwDxgsn9uoHNuiYs0AD8aeK+cpRpF96SvPVxNOdDmW+CrO9neF/Jm1JOZjQYuAJYCI5xz+/1TB4ARfnkksDvwsj2+LFn5njjlOU0HDJHMSdT0tLn8WFbjiPczj8aWyZwVd66nfLjgzsz6A38Bvu+ca3Wnc18TyPj/wsymmFmJmZVUVFRkenNJqUYhkn0Njdn93cU7OEdrFF3xGJBSojCzHkSSxOPOuWd9cZlvNsL/W+7L9wJnBF4+ypclKx8Vp7wN59yDzrnxzrnxxcXFqfyXUtYVd5Jcsa2imsUbI7uTPmUJyomfna9RZDKUvLvgzo9Amg5scM79LvDULCA6cukG4PlA+fV+9NNE4KhvopoLTDKzIb4TexIw1z9XZWYT/bauD7xXzsqBptIua8P+Kp5dEfdcIXT62rMj0cDHxixnimRbS+fArKYmxz3zt3Ckpi5xLFn4rxel8NpLga8Ca8xspS/7EXAH8IyZ3QTsBL7kn5sDXAWUAjXAjQDOuUoz+zmwzK/3M+dcpV/+NjAD6AO86P9ymi68Esm+bNfks3Xh26tbKrhr/mZW7D7MjBsnxD2+ZGN4bKcThXPudRInz8vjrO+AmxO818PAw3HKS4APdDbGMByrbQg7BJFuJxdGPWVC9B7ZizdVUFldFz8l5PLwWInvF7PXhx2CSLfz+NJd2d1g3GFP6d/MT/62rnn5UAdv05oJShRpdrimPuwQJARqcQzXtoPVWd1e3OaeDOwDZVWtk0P8W6FmnhJFmjV20SpwztHHLAGnD+wddgjNMjXNSKJdPqevzJb4GpQoRDIm0TH4cxek91rcA0druWnGMo6fjN/nmOzgnMkDd7yaTPmx2sxt0FOiSLOGxo7dnF26lrDuoSyZ8bt5m1iwsZwXVu2L+3wY33aTc3E3PHP5nraFaaZEkWZqehLJf9HzvYKC+HWY4HDc6Iir6G+/sjrxNQ/5SokizdT0JJI5idv/0/u7iyaCog4kiujSq1si0wdNm7UuzivSEFNTeF1zShRpphqFSPal+2cX/R0XJkgUwX6I6EVwmT5JTHRsUWd2HlKi6J40PDZc6bwyu6auoXlKkIIEVZh4NYrYq6b3HK5JW0wAr5cejLufZeOqdCWKGH9ZvofRU2cnHO3QHnVmZ4c6jyUo1fOzo4Hrn6a/tp3GxuQ1iuD2ogfq4PF68aZyPnLnIl5au590ueDMwaHt90oUAZXVdfzrn1cBsKOTF/Coj0Ik+1KdY23Zjsrm5Y0HjrG14jiQpEYR+J1HNx2MYPnOwwBsOnA8pbi+fPGZ7a6jC+6ybN+RE83LRYWdu2pGiUIkcyzBlRSpNr8E88HJhia2lEcO8IlqFPEM6B2ZOm9AryLqfY2kR1FqV9/F5qn4Ny5KaRMdokQR0LtHy8dx36KtnXqPXGh6Kq+qZW8g6eWrfJqJN38i7Zqa0vizawy8WUdGPUWXv3hR5PY537zs7OZ9N1GNpKNad5qn9FYpUaIICH6pf0twoU17cqFCMeGXC7j0joVhh3FKDh4/yZ+W7GyVHJL1E+VRDpEsSGeHbvBmeYmvo2hZjm56zd6jQKQ1Ivr0KVRI2lVT15DghESd2VmVysddfbKB8qpaGtJ5atON3Pb8Wn7817Ws21fV/srAsh2HMxyR5JN0njgEWwViD/Rr9x5l0cbyuKOelmyrbI4l2oeRqKmso4L/rZseKYm/To7fuKjLSeUDv/q+NygtP06PTvZtdHc7D0WGEnb0OzjZ0JjBaCTfpFqjCL78ivPexZtbDwFtD/Q3P/EOOw/VMP9fLgu8tu22ozWOdE8QGFZzrGoUAbFfQmOTY/TU2TxTsrvd15b6zq/6NNzkffGmcnZXpncMdq6L1iSKCo21e4/yHzNXJ213/vS4EVmKrINS+AEfqalj9Z4j6YulG0pnk+/gvj0C79v6jaMnNK2Hx8aLJ/19FPEeJypLNyWKgNjPe/GmcgB+OHN1VuP42h+XcfnvXsnqNoNq6hrYeSi78/tHFRYYX5+xjKdLdiedFbNHQdfZdb/4wFt89n/eCDuMvJDouJtyjSK4HOcaiaTba3Mwd4HO7JTC6pBsXFvRdX5taRC7T2zP8s1Qguoawuvr+Nofl/Gx3ywOZdsGlB+L3KzFkpyNZWrO/zBEh2JK56WzSSY4xL0j94CIPVA711LLSNQZnk6qUWRZ7NnDee8eBMDw/j3Tvq36xiaq44zqyYW297e3V7a/UoYEv4Fkv7F4iSIXhiZnS01dA2+WHgw7jJyRzqan4H6UKAG1Hh6b+PlkJzsd0ZEE6ICjJ+oz2n+hRBEQ+znX+R1m5OA+ad/Wtx5bznnT5rYp/99Xt6V9W/lgQK/IuIp4o0niif0BvrB6H+fc+iLbKsI5O4+NNdM3k/nhzNX8w0NLu11fViKpd2a3vL4+zlXXbdeP/1qInMRES1KtT8RewFsap/a5YX8VH/rpyzz5dvt9qZ2lRBEQW4W8+fF3ADhUXZf2ZqgFGyP9H7sOtf6hVxwL7wbqp2LSXa/wz0+uSNv7xZsvJ9kZUuwPcM6ayJw6G/YfS1tMqZhw+4JW8wd1xKmcEW4pixwwOjsnWb5K9BHFntUfrq6LW2OP543Sg60SzcpdR+K+b/D9kp3QmFnKF9xtrTjO6KmzeSOm1njweNvjQ3QgyI+eW9OpbXWEEkVA7E4Y/RHuOXyCT/x2cUa2edlvFrV6fCxPfviby453+qLEeKIfffAHmKwlKfb3t2p35GKnjjQJ7ztygvosNFP9efmpneGdyszDXamPJh1ik+wFP5/HR+5s/6LTt7Ye4ssPLeXeBaXNZdH7SsS+b/CGRMGvaubyPW2+u4PHI+sG98fge/3HzNVJfz9feWgpAPuPtq6Z/ns7A2tO1GWm6VqJwivZUcnf//frp/Sa3ZU17Z4FNjU5/vDKVu6at7lD79neWVBZVS2L/GisTMvmmO14NYpkB84/LdnFV6cvbX4cnbKkvbm2SnZUcskdCxNevASRRPKJ3y5Oecr4U63ddGZzukI9Ivg5RE8CDnegRrfDj+5bv7/lQs/g9x78ToId08ETmjte3MhTy3Y1PzaDeevLIq/xGb2hsYkxt8zhk/6E8+mS3Ulr5O8dMaDd2OOpy9AJkBKFd80Db7W7ztETLTve6j1H+OivF7WbXG6btZZfvbiRexZs6VAc7TUlXPzLBdz4x2WMnjq7w8mnsclRsuPUO6izeRCqrY/s4PHm0EnktS1tO3P79SpM+prpr28H4NXNkbPGzWXH2iTES+5YyPaD1fxyzob2AweWbjvEs+/sbVN+qhdfNjnHlEdLOnQmHO2j0XTrEcF9pba+5ay6vWT/9LK2tb7WgyISTJoRs8+UV50MPNd2/ZfWHQBg28HqDp31v7K5ot114snU/XCUKE7Bh376MqOnzuYHT69k1spItbG9KSf+tKTlTGPRxnIOxWljDKo60fGmp44mnwde2co1D7zF0m2HOvze0LkpTT44bS4P+4NxZwT381OZifesYX0BGNi7R9L1Rgzs3by8es8RJt31anPyiPrgyMhotwvOHNyhbf+/B5fEnYTxE+87rUOvj3rff77Ey+vL2HO44xM6djaZn2xo5Imlu1pNl53PWu03gYte22tiXLn7CACnD2rZLxoS1CiCn9Wx2ta/05OB4ey/mbupeTmayO+Z3/JbDZ5wpltNXWaarpUoOuG5FXt5qBMHwxtnLOOiX8xPuk4m2s43l0WaQPYdPbUZZU+16am2vpFjJxv42Qvr2133P/+6Nu5NXVr3UbT/WRyrrW/1umseeItxt72UcP0JY4YCMGnciOb5olbvOdpqnWF+OHTfnm1rJ41Nju89tYIFG8raDESIle4aWX1jE0u2HeK7T65gg28quXv+lk5d1f3fC0r50XNr+NvqlnbyS+9YyP2LOzdrcthW7znCYd+HUOLvBQGR5LulrKUJcOXuI/zihfWtLoqD1tOJB8/KNx041nz7gWB5bK3ggVfif27RlwSvlflYTL9krNmrO3+zo31HMjPaTnM9ZVCikVI/eHpl3HLnHBsPdLxd+9wOtmM2NN+tK/55wfMr9zJqSB+KCgr40BmDW+LpcCR+/VN4wWNLdvLYkp18dOxw/vf68XHf4wv3t98c+MGfvMx9/3BhqxFGNTE/YuccU/+yhqcDU7EUFhi/9Wd+G/a3rhW23C+59ec17raXmt/7eV+j3HHHZxLGlu5mgBlv7OD2mOaw+RvKmL+hjNLbr2TKY8u5+RPncNFZQ9q89rtPrmD/0RP8+VuXAJGRfNC6qXPvkRPc+dJGLnnPsFb7QTzOOWYu38Nnzj+dvj3Tfxh5e3slX/rDWyy79VMUD+jV7vovrj3Ai2sPxH3u03e92vw9fe6+yBXwZxf35/xRg5rX6VHY8l0HaxT3LNjCPQu2sOOOz7S6X829C1s6vwFGDekTtyZ4vLahzcnfySQX0/5k1jpmvLkj4fNhUY0ig4JnMkHPrWjdnj166myqTzbw5+V7WpWP/8W8Vgeb2Ku1O3pTleiO+t0nV/D1GcuASC3jSE3kYPG9p1byhfvf4ur73mhVLY498O89ciLpnf8aO5gpNh5oOTC/tuUgT73d0jzXmTPam594h6qYpoDvP7WC0VNnc/Pj77BgQ3mrJAGRA8sJ35Z9xXnvAmg+I21OrGb8dcVeRk+dzad+90qbBASR7y6R5TsPs//oiU4170y66xXe2XW4ucbknGuT0IJKdh5m4cZyvnD/m5z74xfb7CuzVu3r8Iy7V9/3RrvXoyzdXsm/z1zNT2e1X3vsjGjz5fKdrWNOV5/Mj55b06p/8XBNy4imeAn+tS0V/MNDLYMnYr+LRJ3Pt8/ZwNhbX+xQTNsPVqecJDI1Gk6JIoOmPLa8w+t+ZfrSNnNKHTxex6/nbgQiB+n3/rj1Dhfb2bv/6IlWB65bn1sTuWIzsM5Cf/3GpLte5fP3v9kmjmB1PPqjPFHXyPhfzOPSOxby8STDhDt6Bj357tdaPR7Yp6VfYf6Gsg69R3v+6s/4Z6/ZzzceTTzCCSITEb66uYILfj6P6a9vbz5oNDnH933tL96FTu15+I3tfPhXCzn7R3NYv6+KxZvKmfFGx5osN5cd5/O/f5MP/uRljp9s4PqH3+bZFW07zKOufXBJ8/LJhiaOnKhLuG5HfPK/XuEL97/JPfO3xG2CjI7OW7H7MKXlbU+Iqk828HqcwQYd1ZIQ0pMY7l+8NW6cUUfaGSH11elvJ30+0Q2OOmLxpnIaGpta3Y61szI1AEVNTzmif6/4X8XEMcOY9vxaHnlrZ5vnNh44xlceWspHxw7n/14wkqvuaX0AfnzpLt5/+sA2r4v+8LdVVLeZMqR1513k3z+8urV5XHg8X35oCVvLqzlQ1bH20fe9a0CrJrbNZeHOdVRgxrf+FEnqPw/0rzQ2Oc4u7se2itQvtrz5iXeamyLPGtaPS84ZRq+i5CO0oj4Q5wr+9qR6HwSInM0v33mYAoOrzj+d9xT3b3l///aby47zqd+9yqfHjWBL2TFOH9SHJ6dM5N9nrmLOmgO89sNPcMbQvinHkqo7X9rInS9tbFUWux+m4uX1nTvBWbypnK/9cRlnDevbPDNtLlKNIg2SNT90VLyhnhBpLoqXJKJeLz3Ir17cyI0zljGkX9s5qbZVVLepJo+5ZU7z8q3PrW31XLBW8P7bXmLKoyXtTivyRumhNkli9NTZCede6hPTSZyoIzBbCqxtvwbAil2HqahKz5Xywf6qG2cs41dzNiZZO3UPvLI1blPVwo1lpzxI4b/mbW5u209k3voydhyq4a1thzh+sqE5+Z+oTzwUdNehGlb5UUfz15el1InbGelKEqmI1rrSlSTU9NRNdfRK7XX7quKe+T78xvakwy1nxvSLxDZnvby+jOok477/8bHEzTqx/QaHq+vYWnE81Jlx4zEzPn/ByDbl9y4szdiV8lszPCfV9Ne385l7X6Oqtr7V8N+vzyjh0bd2Nn8Hz6/cx99W7Ws3eRyrbWDa82uTrhP1WuAagCeW7mpOWCcbGvnXZ1Y1n1hd9ptFXH3fGxw8fpJvPFrCzU+8c0r/x66gM6Mnw5DzTU9mNhm4BygEHnLO3RFySF3a1L+0f++N8YEhvnPXJa5y/+jZNXxl4llcdNYQ+vQs5Iq7X22eQjyXBMe9Z8trWw4yeurspKOmUtXk4PyfvNymfNqsdc3Lb2+v5O3tlVz1wdPbfb9H3tpJk4NLzxnWfNvPeP7p8ZYD/ow3dzDjzR0sueVyJv5qQXP5Lc+27Gfj2xky/vK6A3zvqZV87L3F7NQkiEkN6Zv8OqLOsrBurdcRZlYIbAY+DewBlgHXOecSDrUYP368KylJ3nkZz5cfWsIbpad2QZp03Px/+RifCvFmTLnqjKF92F15ate3ZMLFY4ayNMTp5aPuve4Chvfryb/9eRX7jtby+QtGJu3El9ZSOfEws+XOufHxnsv1GsUEoNQ5tw3AzJ4CrgbSPibv0+8fETdRnDm0L7t0FpMyJYn4ciFJADmRJCDSJxekJNFa7x4FnDW0H5viDL2PN3AlXXI9UYwEggPg9wAXx65kZlOAKQBnnnlmpzb0tUvH8PmLRuGcn8dpbHGr5+samjhcU8fOQzU8/Pp2LjlnGNdNOJNps9bxxNJdDOhdxEPXj+c/n1/LVyaexW3Pr2NQnx58ZOxwpk5+H48t2cmkcSPo16uI51bsZXdlDeePGsysVfvadDoWFhifev9pHKtt4M2th3j3oN7UNTYlHXkEcPbwflQcO8k5IyKjU0rLj9OjsICBvYvYcaiGQX168K6BvdlUdoyeRQWcPbxfc4feyMF9mqehKB7Qi6M19dQ1NlE8oBfHauuprW9ieP+e1DU0UVXbQP9eRdQ1NFHX2ERhgdG3Z2HztAbvGti7QyOgehYVNLeVf2DkQAb06sGuyhrOGtaXA1W1bKuoZsKYoRRYZObOHoUF9CwqYHflCUYO6cO28uPNfQjnjxpEZXUdg/r0aDWtyoTRQynZWUmTgxEDe9GnRyH7j9ZydnF/TjY0su/ICYb378Xgvj0oLT/OsH69GDGwF5vLjrf6jAx477sGsO/ICY7U1HPuuwZwpKaOA1W1nD28P03ONb9X7x6FbDt4nKF9ezK0f0/W7q1iUJ8ejD2tPzsOVTd/j717FDTPcRV12oBezc1zxQN60djkqKyuY1i/njgin8PA3kVU1zU2DzwY0rdHhybAG9CriGMnGxjctwcFZq1mQ40a1q9n88V4Iwb2osx35gfLY9+ztqExLfeK74i+PQupqWvkmx8dQ1FhAUdq6ujTo4j6xiZO1DfS5Bz9exVxrLYBs8howre3V1Lf2MTWimrGntafusamuJ3Hl723mPcU96PqRAOFBZGmu9MG9GKJn/rGEfkcohfnORcZmFHX2MTs1fv5P6OHUDygF4bRs6iAmroGyqpO0rMoEufYEQMoMKOhsYnBfXu0uX9Ej0KjvtExYfRQhvTrQVFBAfuPnuCOL5xPbX0jldV1XPKe4fQoNF5eX8boYf2ormug7Ggtn3z/aRRmcErhXG96ugaY7Jz7hn/8VeBi59x3Er2ms01PIiLdWbKmp1wf9bQXOCPweJQvExGRLMn1RLEMGGtmY8ysJ3AtMCvkmEREupWc7qNwzjWY2XeAuUSGxz7snFvXzstERCSNcjpRADjn5gBz2l1RREQyItebnkREJGRKFCIikpQShYiIJKVEISIiSeX0BXedYWYVQOJ5uZMbDnT+biuZlauxKa5Tl6ux5WpckLux5WpccOqxneWcK473RJdLFKkws5JEVyaGLVdjU1ynLldjy9W4IHdjy9W4IL2xqelJRESSUqIQEZGklChaezDsAJLI1dgU16nL1dhyNS7I3dhyNS5IY2zqoxARkaRUoxARkaSUKDwzm2xmm8ys1MymZmF7D5tZuZmtDZQNNbN5ZrbF/zvEl5uZ3etjW21mFwZec4Nff4uZ3ZCGuM4ws0Vmtt7M1pnZ93Iott5m9raZrfKx/dSXjzGzpT6Gp/1Mw5hZL/+41D8/OvBet/jyTWZ2Raqx+fcsNLMVZvZCjsW1w8zWmNlKMyvxZbnwfQ42s5lmttHMNpjZh3MkrnP9ZxX9qzKz7+dIbD/w+/5aM3vS/yYyv58557r9H5GZabcCZwM9gVXAuAxv8zLgQmBtoOzXwFS/PBW40y9fBbwIGDARWOrLhwLb/L9D/PKQFOM6HbjQLw8gcs/ycTkSmwH9/XIPYKnf5jPAtb78AeCf/PK3gQf88rXA0355nP+OewFj/HdfmIbv9F+AJ4AX/ONciWsHMDymLBe+z0eAb/jlnsDgXIgrJsZC4ABwVtixEbnj53agT2D/+lo29rO0fJj5/gd8GJgbeHwLcEsWtjua1oliE3C6Xz4d2OSX/wBcF7secB3wh0B5q/XSFOPzwKdzLTagL/AOkVvjHgSKYr9LItPTf9gvF/n1LPb7Da6XQjyjgAXAJ4EX/HZCj8u/zw7aJopQv09gEJGDnuVSXHHinAS8kQux0XJr6KF+v3kBuCIb+5maniLi3Zt7ZAhxjHDO7ffLB4ARfjlRfBmN21dVLyBy5p4TsfnmnZVAOTCPyNnQEedcQ5ztNMfgnz8KDMtQbHcDPwSiN8EeliNxQeR2zy+b2XKL3F8ewv8+xwAVwB99c91DZtYvB+KKdS3wpF8ONTbn3F7gt8AuYD+R/WY5WdjPlChylIuk+tCGpJlZf+AvwPedc1XB58KMzTnX6Jz7OyJn8BOA94URR5CZ/T1Q7pxbHnYsCXzEOXchcCVws5ldFnwypO+ziEjT6/3OuQuAaiLNOWHH1cy39X8W+HPsc2HE5vtEriaSZN8N9AMmZ2PbShQRuXJv7jIzOx3A/1vuyxPFl5G4zawHkSTxuHPu2VyKLco5dwRYRKSqPdjMojfhCm6nOQb//CDgUAZiuxT4rJntAJ4i0vx0Tw7EBTSfieKcKweeI5Jgw/4+9wB7nHNL/eOZRBJH2HEFXQm845wr84/Dju1TwHbnXIVzrh54lsi+l/H9TIkiIlfuzT0LiI6MuIFI/0C0/Ho/umIicNRXgecCk8xsiD/bmOTLOs3MDJgObHDO/S7HYis2s8F+uQ+RvpMNRBLGNQlii8Z8DbDQnwnOAq71o0LGAGOBtzsbl3PuFufcKOfcaCL7zkLn3JfDjgvAzPqZ2YDoMpHvYS0hf5/OuQPAbjM71xddDqwPO64Y19HS7BSNIczYdgETzayv/51GP7PM72fp6vTJ9z8iIxc2E2nzvjUL23uSSDtjPZGzq5uItB8uALYA84Ghfl0D7vOxrQHGB97n60Cp/7sxDXF9hEiVejWw0v9dlSOxnQ+s8LGtBW7z5Wf7Hb2USDNBL1/e2z8u9c+fHXivW33Mm4Ar0/i9fpyWUU+hx+VjWOX/1kX37Rz5Pv8OKPHf51+JjAwKPS7/nv2InH0PCpSFHhvwU2Cj3/8fIzJyKeP7ma7MFhGRpNT0JCIiSSlRiIhIUkoUIiKSlBKFiIgkpUQhIiJJKVGIiEhSShQiIpKUEoWIiCT1/wFlpjLRbGo9KgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In[29]:\n",
    "\n",
    "\n",
    "df_train['label_sum'].plot()\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25481f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4578c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
